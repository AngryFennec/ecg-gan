{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0264bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -r -N -c -np https://physionet.org/files/ptb-xl/1.0.3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd08b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data/'\n",
    "SAMPLING_RATE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c818ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8f2c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(df, sampling_rate, path):\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "path = PATH\n",
    "sampling_rate=SAMPLING_RATE\n",
    "\n",
    "# load and convert annotation data\n",
    "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load raw signal data\n",
    "#X = load_raw_data(Y, sampling_rate, path)\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
    "\n",
    "# Split data into train and test\n",
    "#test_fold = 10\n",
    "# Train\n",
    "#X_train = X[np.where(Y.strat_fold != test_fold)]\n",
    "#y_train = Y[(Y.strat_fold != test_fold)].diagnostic_superclass\n",
    "# Test\n",
    "#X_test = X[np.where(Y.strat_fold == test_fold)]\n",
    "#y_test = Y[Y.strat_fold == test_fold].diagnostic_superclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce122da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTBDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, path, sampling_rate):\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        self.sampling_rate = sampling_rate\n",
    "        if sampling_rate == 100:\n",
    "            self.data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "        else:\n",
    "            self.data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "        self.data = np.array([signal for signal, meta in self.data])\n",
    "        print(self.data[0])\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal = torch.FloatTensor(self.data[idx])                 \n",
    "        return signal\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b939e103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.119 -0.055  0.064 ... -0.026 -0.039 -0.079]\n",
      " [-0.116 -0.051  0.065 ... -0.031 -0.034 -0.074]\n",
      " [-0.12  -0.044  0.076 ... -0.028 -0.029 -0.069]\n",
      " ...\n",
      " [ 0.069  0.    -0.069 ...  0.024 -0.041 -0.058]\n",
      " [ 0.086  0.004 -0.081 ...  0.242 -0.046 -0.098]\n",
      " [ 0.022 -0.031 -0.054 ...  0.143 -0.035 -0.12 ]]\n"
     ]
    }
   ],
   "source": [
    "dataset = PTBDataset(Y, path, 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a88fd4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "x = dataset[0]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbef17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=128, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b25a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
