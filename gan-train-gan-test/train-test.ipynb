{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b63910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from typing import Tuple, Dict, List\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a1d300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba4515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/mrdbourke/pytorch-deep-learning/blob/main/04_pytorch_custom_datasets.ipynb\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class SignalCustom(Dataset):\n",
    "    \n",
    "    def __init__(self, csv: str) -> None:\n",
    "        self.df = pd.read_csv(csv, sep='\\t')\n",
    "\n",
    "        self.classes, self.class_to_idx = (['norm', 'mi'], {'norm': 0, 'mi': 1})\n",
    "\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(self.df)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, data and label (X, y).\"\n",
    "        st =self.df.at[index, 'signal'].replace('[', '')\n",
    "        st = st.replace(']', '')\n",
    "        st = st.split()\n",
    "        st = [float(i) for i in st]\n",
    "        signal = torch.unsqueeze(torch.from_numpy(np.array(st)), 0)\n",
    "        \n",
    "        class_name  = self.df.at[index, 'mi_class'] \n",
    "        class_idx = int(class_name)\n",
    "        return signal, class_idx # return data, label (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "915a008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data = SignalCustom(csv='./RESULTS/datasets/true-s.csv')\n",
    "conv_data = SignalCustom(csv='./RESULTS/datasets/conv-s.csv')\n",
    "conv_inc_data = SignalCustom(csv='./RESULTS/datasets/conv-inc-s.csv')\n",
    "\n",
    "true_data_test = SignalCustom(csv='./RESULTS/datasets/true-s-test.csv')\n",
    "conv_data_test = SignalCustom(csv='./RESULTS/datasets/conv-s-test.csv')\n",
    "conv_inc_data_test = SignalCustom(csv='./RESULTS/datasets/conv-inc-s-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "05d68e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "true_dl = DataLoader(dataset=true_data, batch_size=64, num_workers=0, shuffle=True) \n",
    "conv_dl = DataLoader(dataset=conv_data, batch_size=64, num_workers=0, shuffle=True)\n",
    "conv_inc_dl = DataLoader(dataset=conv_inc_data, batch_size=64, num_workers=0, shuffle=True)\n",
    "\n",
    "true_dl_test = DataLoader(dataset=true_data_test, batch_size=64, num_workers=0) \n",
    "conv_dl_test = DataLoader(dataset=conv_data_test, batch_size=64, num_workers=0)\n",
    "conv_inc_dl_test = DataLoader(dataset=conv_inc_data_test, batch_size=64, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e93065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 400]) tensor([0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for sign, cls in true_dl:\n",
    "    print(sign.shape, cls)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2871955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class ClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        prices, labels = batch \n",
    "        prices = prices.to(device, dtype=torch.float)\n",
    "        out = self(prices)        \n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        prices, labels = batch \n",
    "        prices = prices.to(device, dtype=torch.float)\n",
    "      \n",
    "        labels = labels.to(device)\n",
    "\n",
    "        out = self(prices)     \n",
    "        out = out.to(device)\n",
    "        \n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "68778e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesCnnModel(ClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2), # output: 64 x 125\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2), # output: 128 x 62\n",
    "\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2), # output: 256 x 31\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(12800, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1d45acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9349c703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TimeSeriesCnnModel                       [1, 2]                    --\n",
       "├─Sequential: 1-1                        [1, 2]                    --\n",
       "│    └─Conv1d: 2-1                       [1, 32, 400]              128\n",
       "│    └─ReLU: 2-2                         [1, 32, 400]              --\n",
       "│    └─Conv1d: 2-3                       [1, 64, 400]              6,208\n",
       "│    └─ReLU: 2-4                         [1, 64, 400]              --\n",
       "│    └─MaxPool1d: 2-5                    [1, 64, 200]              --\n",
       "│    └─Conv1d: 2-6                       [1, 128, 200]             24,704\n",
       "│    └─ReLU: 2-7                         [1, 128, 200]             --\n",
       "│    └─Conv1d: 2-8                       [1, 128, 200]             49,280\n",
       "│    └─ReLU: 2-9                         [1, 128, 200]             --\n",
       "│    └─MaxPool1d: 2-10                   [1, 128, 100]             --\n",
       "│    └─Conv1d: 2-11                      [1, 256, 100]             98,560\n",
       "│    └─ReLU: 2-12                        [1, 256, 100]             --\n",
       "│    └─Conv1d: 2-13                      [1, 256, 100]             196,864\n",
       "│    └─ReLU: 2-14                        [1, 256, 100]             --\n",
       "│    └─MaxPool1d: 2-15                   [1, 256, 50]              --\n",
       "│    └─Flatten: 2-16                     [1, 12800]                --\n",
       "│    └─Linear: 2-17                      [1, 1024]                 13,108,224\n",
       "│    └─ReLU: 2-18                        [1, 1024]                 --\n",
       "│    └─Linear: 2-19                      [1, 512]                  524,800\n",
       "│    └─ReLU: 2-20                        [1, 512]                  --\n",
       "│    └─Linear: 2-21                      [1, 2]                    1,026\n",
       "==========================================================================================\n",
       "Total params: 14,009,794\n",
       "Trainable params: 14,009,794\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 60.51\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 1.14\n",
       "Params size (MB): 56.04\n",
       "Estimated Total Size (MB): 57.18\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = TimeSeriesCnnModel()\n",
    "model1.to(device)\n",
    "    \n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model1, input_size=[1, 1, 400]) # do a test pass through of an example input size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "84c3adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_acc = []\n",
    "        for batch in train_loader:\n",
    "            loss, acc = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            train_acc.append(acc)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()        \n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d6bbbd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "true_dl = DeviceDataLoader(true_dl, device)\n",
    "true_dl_test = DeviceDataLoader(true_dl_test, device)\n",
    "to_device(model1, device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ea7c7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1010\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2fadf8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.6932, val_loss: 0.6931, val_acc: 0.5312\n",
      "Epoch [1], train_loss: 0.6933, val_loss: 0.6928, val_acc: 0.5312\n",
      "Epoch [2], train_loss: 0.6933, val_loss: 0.6932, val_acc: 0.4703\n",
      "Epoch [3], train_loss: 0.6933, val_loss: 0.6930, val_acc: 0.5312\n",
      "Epoch [4], train_loss: 0.6931, val_loss: 0.6931, val_acc: 0.4990\n",
      "Epoch [5], train_loss: 0.6931, val_loss: 0.6931, val_acc: 0.4932\n",
      "Epoch [6], train_loss: 0.6931, val_loss: 0.6929, val_acc: 0.5312\n",
      "Epoch [7], train_loss: 0.6930, val_loss: 0.6928, val_acc: 0.5312\n",
      "Epoch [8], train_loss: 0.6929, val_loss: 0.6925, val_acc: 0.5312\n",
      "Epoch [9], train_loss: 0.6922, val_loss: 0.6931, val_acc: 0.4948\n",
      "Epoch [10], train_loss: 0.6905, val_loss: 0.6922, val_acc: 0.5146\n",
      "Epoch [11], train_loss: 0.6874, val_loss: 0.6901, val_acc: 0.5474\n",
      "Epoch [12], train_loss: 0.6857, val_loss: 0.6922, val_acc: 0.5130\n",
      "Epoch [13], train_loss: 0.6846, val_loss: 0.6937, val_acc: 0.5099\n",
      "Epoch [14], train_loss: 0.6827, val_loss: 0.6968, val_acc: 0.4969\n",
      "Epoch [15], train_loss: 0.6832, val_loss: 0.6936, val_acc: 0.5266\n",
      "Epoch [16], train_loss: 0.6817, val_loss: 0.6950, val_acc: 0.5125\n",
      "Epoch [17], train_loss: 0.6806, val_loss: 0.6980, val_acc: 0.4969\n",
      "Epoch [18], train_loss: 0.6799, val_loss: 0.6973, val_acc: 0.5047\n",
      "Epoch [19], train_loss: 0.6807, val_loss: 0.6986, val_acc: 0.5146\n",
      "Epoch [20], train_loss: 0.6793, val_loss: 0.6991, val_acc: 0.5146\n",
      "Epoch [21], train_loss: 0.6788, val_loss: 0.6978, val_acc: 0.5026\n",
      "Epoch [22], train_loss: 0.6784, val_loss: 0.6994, val_acc: 0.5115\n",
      "Epoch [23], train_loss: 0.6788, val_loss: 0.6983, val_acc: 0.5089\n",
      "Epoch [24], train_loss: 0.6774, val_loss: 0.6992, val_acc: 0.5057\n",
      "Epoch [25], train_loss: 0.6767, val_loss: 0.6991, val_acc: 0.5130\n",
      "Epoch [26], train_loss: 0.6757, val_loss: 0.6996, val_acc: 0.5146\n",
      "Epoch [27], train_loss: 0.6751, val_loss: 0.7008, val_acc: 0.5115\n",
      "Epoch [28], train_loss: 0.6744, val_loss: 0.7009, val_acc: 0.5156\n",
      "Epoch [29], train_loss: 0.6730, val_loss: 0.7037, val_acc: 0.5141\n",
      "Epoch [30], train_loss: 0.6733, val_loss: 0.7027, val_acc: 0.5219\n",
      "Epoch [31], train_loss: 0.6718, val_loss: 0.7040, val_acc: 0.5115\n",
      "Epoch [32], train_loss: 0.6709, val_loss: 0.7041, val_acc: 0.5156\n",
      "Epoch [33], train_loss: 0.6693, val_loss: 0.7041, val_acc: 0.5063\n",
      "Epoch [34], train_loss: 0.6685, val_loss: 0.7061, val_acc: 0.5130\n",
      "Epoch [35], train_loss: 0.6668, val_loss: 0.7096, val_acc: 0.5104\n",
      "Epoch [36], train_loss: 0.6653, val_loss: 0.7076, val_acc: 0.5068\n",
      "Epoch [37], train_loss: 0.6637, val_loss: 0.7106, val_acc: 0.5052\n",
      "Epoch [38], train_loss: 0.6610, val_loss: 0.7115, val_acc: 0.5057\n",
      "Epoch [39], train_loss: 0.6592, val_loss: 0.7135, val_acc: 0.4979\n",
      "Epoch [40], train_loss: 0.6581, val_loss: 0.7155, val_acc: 0.5099\n",
      "Epoch [41], train_loss: 0.6558, val_loss: 0.7167, val_acc: 0.5068\n",
      "Epoch [42], train_loss: 0.6531, val_loss: 0.7175, val_acc: 0.5021\n",
      "Epoch [43], train_loss: 0.6486, val_loss: 0.7203, val_acc: 0.5193\n",
      "Epoch [44], train_loss: 0.6454, val_loss: 0.7243, val_acc: 0.5016\n",
      "Epoch [45], train_loss: 0.6402, val_loss: 0.7231, val_acc: 0.5099\n",
      "Epoch [46], train_loss: 0.6350, val_loss: 0.7250, val_acc: 0.4911\n",
      "Epoch [47], train_loss: 0.6305, val_loss: 0.7366, val_acc: 0.4932\n",
      "Epoch [48], train_loss: 0.6242, val_loss: 0.7312, val_acc: 0.4917\n",
      "Epoch [49], train_loss: 0.6178, val_loss: 0.7409, val_acc: 0.4917\n",
      "Epoch [50], train_loss: 0.6083, val_loss: 0.7342, val_acc: 0.5385\n",
      "Epoch [51], train_loss: 0.6013, val_loss: 0.7355, val_acc: 0.5385\n",
      "Epoch [52], train_loss: 0.5936, val_loss: 0.7331, val_acc: 0.5573\n",
      "Epoch [53], train_loss: 0.5856, val_loss: 0.7394, val_acc: 0.5625\n",
      "Epoch [54], train_loss: 0.5777, val_loss: 0.7491, val_acc: 0.5437\n",
      "Epoch [55], train_loss: 0.5684, val_loss: 0.7546, val_acc: 0.5693\n",
      "Epoch [56], train_loss: 0.5629, val_loss: 0.7518, val_acc: 0.5734\n",
      "Epoch [57], train_loss: 0.5579, val_loss: 0.7653, val_acc: 0.5734\n",
      "Epoch [58], train_loss: 0.5515, val_loss: 0.7657, val_acc: 0.5849\n",
      "Epoch [59], train_loss: 0.5450, val_loss: 0.7710, val_acc: 0.5818\n",
      "Epoch [60], train_loss: 0.5380, val_loss: 0.7870, val_acc: 0.5672\n",
      "Epoch [61], train_loss: 0.5323, val_loss: 0.7834, val_acc: 0.5693\n",
      "Epoch [62], train_loss: 0.5266, val_loss: 0.7860, val_acc: 0.5792\n",
      "Epoch [63], train_loss: 0.5270, val_loss: 0.7871, val_acc: 0.5896\n",
      "Epoch [64], train_loss: 0.5187, val_loss: 0.8161, val_acc: 0.5740\n",
      "Epoch [65], train_loss: 0.5083, val_loss: 0.7997, val_acc: 0.5802\n",
      "Epoch [66], train_loss: 0.4995, val_loss: 0.8044, val_acc: 0.5833\n",
      "Epoch [67], train_loss: 0.4960, val_loss: 0.8457, val_acc: 0.5833\n",
      "Epoch [68], train_loss: 0.4924, val_loss: 0.8271, val_acc: 0.5849\n",
      "Epoch [69], train_loss: 0.4871, val_loss: 0.8342, val_acc: 0.5771\n",
      "Epoch [70], train_loss: 0.4786, val_loss: 0.8525, val_acc: 0.5849\n",
      "Epoch [71], train_loss: 0.4717, val_loss: 0.8425, val_acc: 0.5786\n",
      "Epoch [72], train_loss: 0.4667, val_loss: 0.8613, val_acc: 0.5661\n",
      "Epoch [73], train_loss: 0.4608, val_loss: 0.8895, val_acc: 0.5755\n",
      "Epoch [74], train_loss: 0.4539, val_loss: 0.8676, val_acc: 0.5677\n",
      "Epoch [75], train_loss: 0.4469, val_loss: 0.9039, val_acc: 0.5974\n",
      "Epoch [76], train_loss: 0.4408, val_loss: 0.9077, val_acc: 0.5786\n",
      "Epoch [77], train_loss: 0.4357, val_loss: 0.9187, val_acc: 0.5688\n",
      "Epoch [78], train_loss: 0.4299, val_loss: 0.9386, val_acc: 0.5786\n",
      "Epoch [79], train_loss: 0.4220, val_loss: 0.9245, val_acc: 0.5859\n",
      "Epoch [80], train_loss: 0.4188, val_loss: 0.9397, val_acc: 0.5797\n",
      "Epoch [81], train_loss: 0.4073, val_loss: 0.9529, val_acc: 0.5828\n",
      "Epoch [82], train_loss: 0.3985, val_loss: 1.0032, val_acc: 0.5708\n",
      "Epoch [83], train_loss: 0.3976, val_loss: 0.9790, val_acc: 0.5719\n",
      "Epoch [84], train_loss: 0.3877, val_loss: 0.9928, val_acc: 0.5703\n",
      "Epoch [85], train_loss: 0.3814, val_loss: 1.0277, val_acc: 0.5734\n",
      "Epoch [86], train_loss: 0.3767, val_loss: 1.0561, val_acc: 0.5729\n",
      "Epoch [87], train_loss: 0.3734, val_loss: 1.0649, val_acc: 0.5656\n",
      "Epoch [88], train_loss: 0.3626, val_loss: 1.0673, val_acc: 0.5729\n",
      "Epoch [89], train_loss: 0.3538, val_loss: 1.1037, val_acc: 0.5844\n",
      "Epoch [90], train_loss: 0.3480, val_loss: 1.1157, val_acc: 0.5635\n",
      "Epoch [91], train_loss: 0.3454, val_loss: 1.0833, val_acc: 0.5797\n",
      "Epoch [92], train_loss: 0.3351, val_loss: 1.1071, val_acc: 0.5766\n",
      "Epoch [93], train_loss: 0.3274, val_loss: 1.1056, val_acc: 0.5813\n",
      "Epoch [94], train_loss: 0.3168, val_loss: 1.1461, val_acc: 0.5755\n",
      "Epoch [95], train_loss: 0.3147, val_loss: 1.1667, val_acc: 0.5760\n",
      "Epoch [96], train_loss: 0.3096, val_loss: 1.2082, val_acc: 0.5677\n",
      "Epoch [97], train_loss: 0.3077, val_loss: 1.1848, val_acc: 0.5719\n",
      "Epoch [98], train_loss: 0.2960, val_loss: 1.2485, val_acc: 0.5818\n",
      "Epoch [99], train_loss: 0.2894, val_loss: 1.2928, val_acc: 0.5698\n",
      "Epoch [100], train_loss: 0.2830, val_loss: 1.2720, val_acc: 0.5729\n",
      "Epoch [101], train_loss: 0.2872, val_loss: 1.3148, val_acc: 0.5740\n",
      "Epoch [102], train_loss: 0.2711, val_loss: 1.3224, val_acc: 0.5823\n",
      "Epoch [103], train_loss: 0.2629, val_loss: 1.3260, val_acc: 0.5714\n",
      "Epoch [104], train_loss: 0.2560, val_loss: 1.3713, val_acc: 0.5682\n",
      "Epoch [105], train_loss: 0.2510, val_loss: 1.3764, val_acc: 0.5505\n",
      "Epoch [106], train_loss: 0.2467, val_loss: 1.3965, val_acc: 0.5708\n",
      "Epoch [107], train_loss: 0.2396, val_loss: 1.4382, val_acc: 0.5724\n",
      "Epoch [108], train_loss: 0.2393, val_loss: 1.4210, val_acc: 0.5531\n",
      "Epoch [109], train_loss: 0.2280, val_loss: 1.4610, val_acc: 0.5760\n",
      "Epoch [110], train_loss: 0.2236, val_loss: 1.5112, val_acc: 0.5594\n",
      "Epoch [111], train_loss: 0.2198, val_loss: 1.5231, val_acc: 0.5781\n",
      "Epoch [112], train_loss: 0.2156, val_loss: 1.5762, val_acc: 0.5536\n",
      "Epoch [113], train_loss: 0.2053, val_loss: 1.5809, val_acc: 0.5656\n",
      "Epoch [114], train_loss: 0.1990, val_loss: 1.6675, val_acc: 0.5651\n",
      "Epoch [115], train_loss: 0.1973, val_loss: 1.7105, val_acc: 0.5724\n",
      "Epoch [116], train_loss: 0.2049, val_loss: 1.7237, val_acc: 0.5641\n",
      "Epoch [117], train_loss: 0.1872, val_loss: 1.7169, val_acc: 0.5698\n",
      "Epoch [118], train_loss: 0.1822, val_loss: 1.7444, val_acc: 0.5708\n",
      "Epoch [119], train_loss: 0.1801, val_loss: 1.7353, val_acc: 0.5536\n",
      "Epoch [120], train_loss: 0.1730, val_loss: 1.8005, val_acc: 0.5703\n",
      "Epoch [121], train_loss: 0.1690, val_loss: 1.8214, val_acc: 0.5599\n",
      "Epoch [122], train_loss: 0.1613, val_loss: 1.8105, val_acc: 0.5552\n",
      "Epoch [123], train_loss: 0.1556, val_loss: 1.8670, val_acc: 0.5708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124], train_loss: 0.1570, val_loss: 1.8834, val_acc: 0.5432\n",
      "Epoch [125], train_loss: 0.1453, val_loss: 1.9184, val_acc: 0.5771\n",
      "Epoch [126], train_loss: 0.1428, val_loss: 1.9244, val_acc: 0.5562\n",
      "Epoch [127], train_loss: 0.1433, val_loss: 2.0104, val_acc: 0.5615\n",
      "Epoch [128], train_loss: 0.1349, val_loss: 2.0206, val_acc: 0.5568\n",
      "Epoch [129], train_loss: 0.1304, val_loss: 2.1181, val_acc: 0.5458\n",
      "Epoch [130], train_loss: 0.1303, val_loss: 2.1232, val_acc: 0.5651\n",
      "Epoch [131], train_loss: 0.1316, val_loss: 2.1432, val_acc: 0.5391\n",
      "Epoch [132], train_loss: 0.1248, val_loss: 2.1778, val_acc: 0.5547\n",
      "Epoch [133], train_loss: 0.1174, val_loss: 2.2613, val_acc: 0.5490\n",
      "Epoch [134], train_loss: 0.1286, val_loss: 2.2684, val_acc: 0.5193\n",
      "Epoch [135], train_loss: 0.1299, val_loss: 2.3095, val_acc: 0.5417\n",
      "Epoch [136], train_loss: 0.1219, val_loss: 2.4426, val_acc: 0.5417\n",
      "Epoch [137], train_loss: 0.1171, val_loss: 2.4038, val_acc: 0.5583\n",
      "Epoch [138], train_loss: 0.1050, val_loss: 2.4163, val_acc: 0.5542\n",
      "Epoch [139], train_loss: 0.1024, val_loss: 2.3708, val_acc: 0.5427\n",
      "Epoch [140], train_loss: 0.1098, val_loss: 2.4220, val_acc: 0.5443\n",
      "Epoch [141], train_loss: 0.0996, val_loss: 2.4592, val_acc: 0.5547\n",
      "Epoch [142], train_loss: 0.0894, val_loss: 2.5162, val_acc: 0.5615\n",
      "Epoch [143], train_loss: 0.0895, val_loss: 2.5029, val_acc: 0.5490\n",
      "Epoch [144], train_loss: 0.0837, val_loss: 2.5971, val_acc: 0.5573\n",
      "Epoch [145], train_loss: 0.0799, val_loss: 2.5820, val_acc: 0.5547\n",
      "Epoch [146], train_loss: 0.0815, val_loss: 2.6300, val_acc: 0.5458\n",
      "Epoch [147], train_loss: 0.0804, val_loss: 2.7272, val_acc: 0.5635\n",
      "Epoch [148], train_loss: 0.0899, val_loss: 2.6692, val_acc: 0.5271\n",
      "Epoch [149], train_loss: 0.0918, val_loss: 2.7019, val_acc: 0.5547\n",
      "Epoch [150], train_loss: 0.0841, val_loss: 2.8123, val_acc: 0.5469\n",
      "Epoch [151], train_loss: 0.0726, val_loss: 2.7854, val_acc: 0.5391\n",
      "Epoch [152], train_loss: 0.0714, val_loss: 2.8050, val_acc: 0.5427\n",
      "Epoch [153], train_loss: 0.0625, val_loss: 2.8656, val_acc: 0.5370\n",
      "Epoch [154], train_loss: 0.0579, val_loss: 2.9337, val_acc: 0.5380\n",
      "Epoch [155], train_loss: 0.0587, val_loss: 2.9593, val_acc: 0.5349\n",
      "Epoch [156], train_loss: 0.0547, val_loss: 2.9973, val_acc: 0.5328\n",
      "Epoch [157], train_loss: 0.0549, val_loss: 2.9700, val_acc: 0.5339\n",
      "Epoch [158], train_loss: 0.0538, val_loss: 3.0865, val_acc: 0.5422\n",
      "Epoch [159], train_loss: 0.0507, val_loss: 3.1523, val_acc: 0.5359\n",
      "Epoch [160], train_loss: 0.0504, val_loss: 3.1483, val_acc: 0.5557\n",
      "Epoch [161], train_loss: 0.0515, val_loss: 3.1820, val_acc: 0.5443\n",
      "Epoch [162], train_loss: 0.0441, val_loss: 3.2937, val_acc: 0.5359\n",
      "Epoch [163], train_loss: 0.0515, val_loss: 3.3654, val_acc: 0.5292\n",
      "Epoch [164], train_loss: 0.0437, val_loss: 3.3485, val_acc: 0.5490\n",
      "Epoch [165], train_loss: 0.0436, val_loss: 3.3656, val_acc: 0.5474\n",
      "Epoch [166], train_loss: 0.0414, val_loss: 3.4213, val_acc: 0.5516\n",
      "Epoch [167], train_loss: 0.0386, val_loss: 3.3769, val_acc: 0.5344\n",
      "Epoch [168], train_loss: 0.0342, val_loss: 3.4728, val_acc: 0.5286\n",
      "Epoch [169], train_loss: 0.0330, val_loss: 3.5089, val_acc: 0.5479\n",
      "Epoch [170], train_loss: 0.0318, val_loss: 3.5740, val_acc: 0.5375\n",
      "Epoch [171], train_loss: 0.0316, val_loss: 3.5962, val_acc: 0.5312\n",
      "Epoch [172], train_loss: 0.0303, val_loss: 3.6901, val_acc: 0.5385\n",
      "Epoch [173], train_loss: 0.0284, val_loss: 3.6716, val_acc: 0.5464\n",
      "Epoch [174], train_loss: 0.0272, val_loss: 3.7239, val_acc: 0.5406\n",
      "Epoch [175], train_loss: 0.0278, val_loss: 3.8263, val_acc: 0.5432\n",
      "Epoch [176], train_loss: 0.0264, val_loss: 3.7955, val_acc: 0.5245\n",
      "Epoch [177], train_loss: 0.0715, val_loss: 4.3067, val_acc: 0.5599\n",
      "Epoch [178], train_loss: 0.1327, val_loss: 4.0719, val_acc: 0.5453\n",
      "Epoch [179], train_loss: 0.0764, val_loss: 4.0747, val_acc: 0.5422\n",
      "Epoch [180], train_loss: 0.0643, val_loss: 4.2264, val_acc: 0.5292\n",
      "Epoch [181], train_loss: 0.1266, val_loss: 4.4710, val_acc: 0.5094\n",
      "Epoch [182], train_loss: 0.0697, val_loss: 3.7715, val_acc: 0.5422\n",
      "Epoch [183], train_loss: 0.0289, val_loss: 3.8614, val_acc: 0.5469\n",
      "Epoch [184], train_loss: 0.0263, val_loss: 3.8912, val_acc: 0.5464\n",
      "Epoch [185], train_loss: 0.0227, val_loss: 3.9015, val_acc: 0.5365\n",
      "Epoch [186], train_loss: 0.0220, val_loss: 3.9468, val_acc: 0.5328\n",
      "Epoch [187], train_loss: 0.0205, val_loss: 3.9708, val_acc: 0.5380\n",
      "Epoch [188], train_loss: 0.0200, val_loss: 4.0096, val_acc: 0.5333\n",
      "Epoch [189], train_loss: 0.0199, val_loss: 4.0523, val_acc: 0.5359\n",
      "Epoch [190], train_loss: 0.0188, val_loss: 4.1157, val_acc: 0.5370\n",
      "Epoch [191], train_loss: 0.0190, val_loss: 4.1107, val_acc: 0.5245\n",
      "Epoch [192], train_loss: 0.0185, val_loss: 4.1604, val_acc: 0.5349\n",
      "Epoch [193], train_loss: 0.0185, val_loss: 4.1767, val_acc: 0.5406\n",
      "Epoch [194], train_loss: 0.0160, val_loss: 4.1984, val_acc: 0.5349\n",
      "Epoch [195], train_loss: 0.0161, val_loss: 4.2106, val_acc: 0.5302\n",
      "Epoch [196], train_loss: 0.0170, val_loss: 4.3019, val_acc: 0.5354\n",
      "Epoch [197], train_loss: 0.0157, val_loss: 4.2641, val_acc: 0.5359\n",
      "Epoch [198], train_loss: 0.0146, val_loss: 4.3374, val_acc: 0.5333\n",
      "Epoch [199], train_loss: 0.0146, val_loss: 4.3588, val_acc: 0.5422\n",
      "Epoch [200], train_loss: 0.0137, val_loss: 4.3552, val_acc: 0.5312\n",
      "Epoch [201], train_loss: 0.0136, val_loss: 4.3949, val_acc: 0.5307\n",
      "Epoch [202], train_loss: 0.0134, val_loss: 4.4719, val_acc: 0.5359\n",
      "Epoch [203], train_loss: 0.0136, val_loss: 4.4916, val_acc: 0.5396\n",
      "Epoch [204], train_loss: 0.0114, val_loss: 4.4981, val_acc: 0.5333\n",
      "Epoch [205], train_loss: 0.0109, val_loss: 4.5337, val_acc: 0.5292\n",
      "Epoch [206], train_loss: 0.0105, val_loss: 4.5793, val_acc: 0.5365\n",
      "Epoch [207], train_loss: 0.0102, val_loss: 4.6092, val_acc: 0.5307\n",
      "Epoch [208], train_loss: 0.0105, val_loss: 4.6298, val_acc: 0.5385\n",
      "Epoch [209], train_loss: 0.0101, val_loss: 4.6415, val_acc: 0.5339\n",
      "Epoch [210], train_loss: 0.0099, val_loss: 4.6972, val_acc: 0.5370\n",
      "Epoch [211], train_loss: 0.0091, val_loss: 4.7041, val_acc: 0.5365\n",
      "Epoch [212], train_loss: 0.0097, val_loss: 4.7426, val_acc: 0.5339\n",
      "Epoch [213], train_loss: 0.0083, val_loss: 4.7784, val_acc: 0.5349\n",
      "Epoch [214], train_loss: 0.0088, val_loss: 4.8219, val_acc: 0.5307\n",
      "Epoch [215], train_loss: 0.0087, val_loss: 4.8289, val_acc: 0.5323\n",
      "Epoch [216], train_loss: 0.0080, val_loss: 4.8690, val_acc: 0.5323\n",
      "Epoch [217], train_loss: 0.0077, val_loss: 4.9061, val_acc: 0.5385\n",
      "Epoch [218], train_loss: 0.0071, val_loss: 4.9647, val_acc: 0.5391\n",
      "Epoch [219], train_loss: 0.0079, val_loss: 4.9717, val_acc: 0.5406\n",
      "Epoch [220], train_loss: 0.0071, val_loss: 5.0165, val_acc: 0.5375\n",
      "Epoch [221], train_loss: 0.0095, val_loss: 5.0901, val_acc: 0.5401\n",
      "Epoch [222], train_loss: 0.0067, val_loss: 5.0700, val_acc: 0.5354\n",
      "Epoch [223], train_loss: 0.0060, val_loss: 5.1133, val_acc: 0.5375\n",
      "Epoch [224], train_loss: 0.0058, val_loss: 5.1159, val_acc: 0.5323\n",
      "Epoch [225], train_loss: 0.0054, val_loss: 5.1642, val_acc: 0.5365\n",
      "Epoch [226], train_loss: 0.0055, val_loss: 5.2531, val_acc: 0.5370\n",
      "Epoch [227], train_loss: 0.0050, val_loss: 5.2047, val_acc: 0.5292\n",
      "Epoch [228], train_loss: 0.0050, val_loss: 5.2440, val_acc: 0.5344\n",
      "Epoch [229], train_loss: 0.0045, val_loss: 5.2807, val_acc: 0.5307\n",
      "Epoch [230], train_loss: 0.0046, val_loss: 5.3105, val_acc: 0.5307\n",
      "Epoch [231], train_loss: 0.0052, val_loss: 5.3584, val_acc: 0.5333\n",
      "Epoch [232], train_loss: 0.0042, val_loss: 5.3788, val_acc: 0.5365\n",
      "Epoch [233], train_loss: 0.0039, val_loss: 5.4515, val_acc: 0.5312\n",
      "Epoch [234], train_loss: 0.0040, val_loss: 5.4178, val_acc: 0.5396\n",
      "Epoch [235], train_loss: 0.0041, val_loss: 5.5051, val_acc: 0.5354\n",
      "Epoch [236], train_loss: 0.0036, val_loss: 5.5256, val_acc: 0.5349\n",
      "Epoch [237], train_loss: 0.0035, val_loss: 5.5251, val_acc: 0.5307\n",
      "Epoch [238], train_loss: 0.0034, val_loss: 5.5554, val_acc: 0.5396\n",
      "Epoch [239], train_loss: 0.0032, val_loss: 5.5713, val_acc: 0.5318\n",
      "Epoch [240], train_loss: 0.0033, val_loss: 5.6350, val_acc: 0.5432\n",
      "Epoch [241], train_loss: 0.0032, val_loss: 5.7002, val_acc: 0.5401\n",
      "Epoch [242], train_loss: 0.0029, val_loss: 5.7136, val_acc: 0.5406\n",
      "Epoch [243], train_loss: 0.0029, val_loss: 5.7572, val_acc: 0.5401\n",
      "Epoch [244], train_loss: 0.0025, val_loss: 5.7957, val_acc: 0.5370\n",
      "Epoch [245], train_loss: 0.0024, val_loss: 5.7649, val_acc: 0.5380\n",
      "Epoch [246], train_loss: 0.0023, val_loss: 5.8194, val_acc: 0.5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [247], train_loss: 0.0023, val_loss: 5.8922, val_acc: 0.5370\n",
      "Epoch [248], train_loss: 0.0024, val_loss: 5.9017, val_acc: 0.5432\n",
      "Epoch [249], train_loss: 0.0025, val_loss: 5.9128, val_acc: 0.5385\n",
      "Epoch [250], train_loss: 0.0021, val_loss: 5.9624, val_acc: 0.5370\n",
      "Epoch [251], train_loss: 0.0020, val_loss: 5.9931, val_acc: 0.5385\n",
      "Epoch [252], train_loss: 0.0019, val_loss: 5.9958, val_acc: 0.5401\n",
      "Epoch [253], train_loss: 0.0018, val_loss: 6.0513, val_acc: 0.5469\n",
      "Epoch [254], train_loss: 0.0018, val_loss: 6.0506, val_acc: 0.5333\n",
      "Epoch [255], train_loss: 0.0018, val_loss: 6.1013, val_acc: 0.5448\n",
      "Epoch [256], train_loss: 0.0016, val_loss: 6.1593, val_acc: 0.5437\n",
      "Epoch [257], train_loss: 0.0016, val_loss: 6.1455, val_acc: 0.5359\n",
      "Epoch [258], train_loss: 0.0015, val_loss: 6.2008, val_acc: 0.5354\n",
      "Epoch [259], train_loss: 0.0014, val_loss: 6.2180, val_acc: 0.5354\n",
      "Epoch [260], train_loss: 0.0014, val_loss: 6.2672, val_acc: 0.5417\n",
      "Epoch [261], train_loss: 0.0014, val_loss: 6.3370, val_acc: 0.5385\n",
      "Epoch [262], train_loss: 0.0017, val_loss: 6.4010, val_acc: 0.5437\n",
      "Epoch [263], train_loss: 0.0016, val_loss: 6.3217, val_acc: 0.5349\n",
      "Epoch [264], train_loss: 0.0021, val_loss: 6.4584, val_acc: 0.5354\n",
      "Epoch [265], train_loss: 0.3220, val_loss: 6.2006, val_acc: 0.5318\n",
      "Epoch [266], train_loss: 0.1327, val_loss: 5.9572, val_acc: 0.5297\n",
      "Epoch [267], train_loss: 0.0480, val_loss: 5.7789, val_acc: 0.5526\n",
      "Epoch [268], train_loss: 0.0169, val_loss: 5.5407, val_acc: 0.5422\n",
      "Epoch [269], train_loss: 0.0081, val_loss: 5.6000, val_acc: 0.5375\n",
      "Epoch [270], train_loss: 0.0043, val_loss: 5.5740, val_acc: 0.5589\n",
      "Epoch [271], train_loss: 0.0032, val_loss: 5.5903, val_acc: 0.5510\n",
      "Epoch [272], train_loss: 0.0029, val_loss: 5.6074, val_acc: 0.5458\n",
      "Epoch [273], train_loss: 0.0027, val_loss: 5.6278, val_acc: 0.5354\n",
      "Epoch [274], train_loss: 0.0025, val_loss: 5.6477, val_acc: 0.5427\n",
      "Epoch [275], train_loss: 0.0024, val_loss: 5.6691, val_acc: 0.5443\n",
      "Epoch [276], train_loss: 0.0023, val_loss: 5.6828, val_acc: 0.5427\n",
      "Epoch [277], train_loss: 0.0022, val_loss: 5.6957, val_acc: 0.5339\n",
      "Epoch [278], train_loss: 0.0021, val_loss: 5.7111, val_acc: 0.5385\n",
      "Epoch [279], train_loss: 0.0021, val_loss: 5.7210, val_acc: 0.5458\n",
      "Epoch [280], train_loss: 0.0020, val_loss: 5.7380, val_acc: 0.5401\n",
      "Epoch [281], train_loss: 0.0019, val_loss: 5.7664, val_acc: 0.5385\n",
      "Epoch [282], train_loss: 0.0019, val_loss: 5.7698, val_acc: 0.5417\n",
      "Epoch [283], train_loss: 0.0018, val_loss: 5.7830, val_acc: 0.5443\n",
      "Epoch [284], train_loss: 0.0018, val_loss: 5.7943, val_acc: 0.5411\n",
      "Epoch [285], train_loss: 0.0018, val_loss: 5.8081, val_acc: 0.5474\n",
      "Epoch [286], train_loss: 0.0017, val_loss: 5.8257, val_acc: 0.5432\n",
      "Epoch [287], train_loss: 0.0017, val_loss: 5.8384, val_acc: 0.5432\n",
      "Epoch [288], train_loss: 0.0017, val_loss: 5.8483, val_acc: 0.5401\n",
      "Epoch [289], train_loss: 0.0016, val_loss: 5.8584, val_acc: 0.5417\n",
      "Epoch [290], train_loss: 0.0016, val_loss: 5.8748, val_acc: 0.5417\n",
      "Epoch [291], train_loss: 0.0015, val_loss: 5.8977, val_acc: 0.5385\n",
      "Epoch [292], train_loss: 0.0015, val_loss: 5.8972, val_acc: 0.5396\n",
      "Epoch [293], train_loss: 0.0015, val_loss: 5.9275, val_acc: 0.5432\n",
      "Epoch [294], train_loss: 0.0014, val_loss: 5.9297, val_acc: 0.5385\n",
      "Epoch [295], train_loss: 0.0015, val_loss: 5.9451, val_acc: 0.5417\n",
      "Epoch [296], train_loss: 0.0015, val_loss: 5.9520, val_acc: 0.5370\n",
      "Epoch [297], train_loss: 0.0014, val_loss: 5.9741, val_acc: 0.5385\n",
      "Epoch [298], train_loss: 0.0013, val_loss: 5.9890, val_acc: 0.5354\n",
      "Epoch [299], train_loss: 0.0013, val_loss: 5.9957, val_acc: 0.5370\n",
      "Epoch [300], train_loss: 0.0013, val_loss: 6.0162, val_acc: 0.5370\n",
      "Epoch [301], train_loss: 0.0012, val_loss: 6.0210, val_acc: 0.5385\n",
      "Epoch [302], train_loss: 0.0013, val_loss: 6.0584, val_acc: 0.5432\n",
      "Epoch [303], train_loss: 0.0012, val_loss: 6.0748, val_acc: 0.5464\n",
      "Epoch [304], train_loss: 0.0012, val_loss: 6.0731, val_acc: 0.5417\n",
      "Epoch [305], train_loss: 0.0011, val_loss: 6.0827, val_acc: 0.5396\n",
      "Epoch [306], train_loss: 0.0011, val_loss: 6.0997, val_acc: 0.5354\n",
      "Epoch [307], train_loss: 0.0011, val_loss: 6.1132, val_acc: 0.5370\n",
      "Epoch [308], train_loss: 0.0011, val_loss: 6.1281, val_acc: 0.5385\n",
      "Epoch [309], train_loss: 0.0011, val_loss: 6.1455, val_acc: 0.5401\n",
      "Epoch [310], train_loss: 0.0010, val_loss: 6.1505, val_acc: 0.5380\n",
      "Epoch [311], train_loss: 0.0010, val_loss: 6.1597, val_acc: 0.5354\n",
      "Epoch [312], train_loss: 0.0010, val_loss: 6.1833, val_acc: 0.5370\n",
      "Epoch [313], train_loss: 0.0010, val_loss: 6.1956, val_acc: 0.5354\n",
      "Epoch [314], train_loss: 0.0010, val_loss: 6.2023, val_acc: 0.5380\n",
      "Epoch [315], train_loss: 0.0010, val_loss: 6.2210, val_acc: 0.5380\n",
      "Epoch [316], train_loss: 0.0009, val_loss: 6.2447, val_acc: 0.5370\n",
      "Epoch [317], train_loss: 0.0009, val_loss: 6.2643, val_acc: 0.5432\n",
      "Epoch [318], train_loss: 0.0009, val_loss: 6.2718, val_acc: 0.5401\n",
      "Epoch [319], train_loss: 0.0009, val_loss: 6.2908, val_acc: 0.5432\n",
      "Epoch [320], train_loss: 0.0009, val_loss: 6.2966, val_acc: 0.5354\n",
      "Epoch [321], train_loss: 0.0009, val_loss: 6.3223, val_acc: 0.5432\n",
      "Epoch [322], train_loss: 0.0008, val_loss: 6.3357, val_acc: 0.5354\n",
      "Epoch [323], train_loss: 0.0009, val_loss: 6.3409, val_acc: 0.5339\n",
      "Epoch [324], train_loss: 0.0008, val_loss: 6.3640, val_acc: 0.5354\n",
      "Epoch [325], train_loss: 0.0008, val_loss: 6.3802, val_acc: 0.5339\n",
      "Epoch [326], train_loss: 0.0008, val_loss: 6.4068, val_acc: 0.5464\n",
      "Epoch [327], train_loss: 0.0008, val_loss: 6.4093, val_acc: 0.5354\n",
      "Epoch [328], train_loss: 0.0008, val_loss: 6.4327, val_acc: 0.5401\n",
      "Epoch [329], train_loss: 0.0007, val_loss: 6.4386, val_acc: 0.5323\n",
      "Epoch [330], train_loss: 0.0007, val_loss: 6.4581, val_acc: 0.5354\n",
      "Epoch [331], train_loss: 0.0007, val_loss: 6.4670, val_acc: 0.5349\n",
      "Epoch [332], train_loss: 0.0007, val_loss: 6.4863, val_acc: 0.5307\n",
      "Epoch [333], train_loss: 0.0007, val_loss: 6.5142, val_acc: 0.5448\n",
      "Epoch [334], train_loss: 0.0007, val_loss: 6.5296, val_acc: 0.5432\n",
      "Epoch [335], train_loss: 0.0007, val_loss: 6.5459, val_acc: 0.5385\n",
      "Epoch [336], train_loss: 0.0006, val_loss: 6.5529, val_acc: 0.5354\n",
      "Epoch [337], train_loss: 0.0006, val_loss: 6.5675, val_acc: 0.5333\n",
      "Epoch [338], train_loss: 0.0006, val_loss: 6.5919, val_acc: 0.5354\n",
      "Epoch [339], train_loss: 0.0006, val_loss: 6.6079, val_acc: 0.5370\n",
      "Epoch [340], train_loss: 0.0006, val_loss: 6.6092, val_acc: 0.5333\n",
      "Epoch [341], train_loss: 0.0006, val_loss: 6.6287, val_acc: 0.5385\n",
      "Epoch [342], train_loss: 0.0006, val_loss: 6.6499, val_acc: 0.5385\n",
      "Epoch [343], train_loss: 0.0005, val_loss: 6.6798, val_acc: 0.5417\n",
      "Epoch [344], train_loss: 0.0005, val_loss: 6.6913, val_acc: 0.5432\n",
      "Epoch [345], train_loss: 0.0005, val_loss: 6.7045, val_acc: 0.5307\n",
      "Epoch [346], train_loss: 0.0005, val_loss: 6.7098, val_acc: 0.5276\n",
      "Epoch [347], train_loss: 0.0005, val_loss: 6.7327, val_acc: 0.5380\n",
      "Epoch [348], train_loss: 0.0005, val_loss: 6.7446, val_acc: 0.5323\n",
      "Epoch [349], train_loss: 0.0005, val_loss: 6.7675, val_acc: 0.5323\n",
      "Epoch [350], train_loss: 0.0005, val_loss: 6.7931, val_acc: 0.5323\n",
      "Epoch [351], train_loss: 0.0005, val_loss: 6.8012, val_acc: 0.5370\n",
      "Epoch [352], train_loss: 0.0005, val_loss: 6.8228, val_acc: 0.5370\n",
      "Epoch [353], train_loss: 0.0004, val_loss: 6.8460, val_acc: 0.5417\n",
      "Epoch [354], train_loss: 0.0004, val_loss: 6.8528, val_acc: 0.5339\n",
      "Epoch [355], train_loss: 0.0004, val_loss: 6.8853, val_acc: 0.5432\n",
      "Epoch [356], train_loss: 0.0004, val_loss: 6.9003, val_acc: 0.5385\n",
      "Epoch [357], train_loss: 0.0004, val_loss: 6.9194, val_acc: 0.5307\n",
      "Epoch [358], train_loss: 0.0004, val_loss: 6.9171, val_acc: 0.5260\n",
      "Epoch [359], train_loss: 0.0004, val_loss: 6.9459, val_acc: 0.5307\n",
      "Epoch [360], train_loss: 0.0004, val_loss: 6.9707, val_acc: 0.5339\n",
      "Epoch [361], train_loss: 0.0004, val_loss: 7.0040, val_acc: 0.5406\n",
      "Epoch [362], train_loss: 0.0004, val_loss: 7.0034, val_acc: 0.5260\n",
      "Epoch [363], train_loss: 0.0004, val_loss: 7.0268, val_acc: 0.5354\n",
      "Epoch [364], train_loss: 0.0003, val_loss: 7.0401, val_acc: 0.5307\n",
      "Epoch [365], train_loss: 0.0003, val_loss: 7.0749, val_acc: 0.5422\n",
      "Epoch [366], train_loss: 0.0004, val_loss: 7.0965, val_acc: 0.5464\n",
      "Epoch [367], train_loss: 0.0003, val_loss: 7.1001, val_acc: 0.5292\n",
      "Epoch [368], train_loss: 0.0003, val_loss: 7.1104, val_acc: 0.5339\n",
      "Epoch [369], train_loss: 0.0003, val_loss: 7.1359, val_acc: 0.5307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [370], train_loss: 0.0003, val_loss: 7.1734, val_acc: 0.5432\n",
      "Epoch [371], train_loss: 0.0003, val_loss: 7.1865, val_acc: 0.5406\n",
      "Epoch [372], train_loss: 0.0003, val_loss: 7.1929, val_acc: 0.5323\n",
      "Epoch [373], train_loss: 0.0003, val_loss: 7.2063, val_acc: 0.5276\n",
      "Epoch [374], train_loss: 0.0003, val_loss: 7.2271, val_acc: 0.5323\n",
      "Epoch [375], train_loss: 0.0003, val_loss: 7.2427, val_acc: 0.5354\n",
      "Epoch [376], train_loss: 0.0002, val_loss: 7.3047, val_acc: 0.5359\n",
      "Epoch [377], train_loss: 0.0003, val_loss: 7.2809, val_acc: 0.5354\n",
      "Epoch [378], train_loss: 0.0002, val_loss: 7.3063, val_acc: 0.5292\n",
      "Epoch [379], train_loss: 0.0002, val_loss: 7.3188, val_acc: 0.5354\n",
      "Epoch [380], train_loss: 0.0002, val_loss: 7.3606, val_acc: 0.5417\n",
      "Epoch [381], train_loss: 0.0002, val_loss: 7.3747, val_acc: 0.5385\n",
      "Epoch [382], train_loss: 0.0002, val_loss: 7.3942, val_acc: 0.5385\n",
      "Epoch [383], train_loss: 0.0002, val_loss: 7.4173, val_acc: 0.5391\n",
      "Epoch [384], train_loss: 0.0002, val_loss: 7.4344, val_acc: 0.5464\n",
      "Epoch [385], train_loss: 0.0002, val_loss: 7.4410, val_acc: 0.5307\n",
      "Epoch [386], train_loss: 0.0002, val_loss: 7.4814, val_acc: 0.5375\n",
      "Epoch [387], train_loss: 0.0002, val_loss: 7.4750, val_acc: 0.5292\n",
      "Epoch [388], train_loss: 0.0002, val_loss: 7.5162, val_acc: 0.5344\n",
      "Epoch [389], train_loss: 0.0002, val_loss: 7.5312, val_acc: 0.5370\n",
      "Epoch [390], train_loss: 0.0002, val_loss: 7.5441, val_acc: 0.5339\n",
      "Epoch [391], train_loss: 0.0002, val_loss: 7.5824, val_acc: 0.5359\n",
      "Epoch [392], train_loss: 0.0002, val_loss: 7.5771, val_acc: 0.5339\n",
      "Epoch [393], train_loss: 0.0002, val_loss: 7.6041, val_acc: 0.5370\n",
      "Epoch [394], train_loss: 0.0002, val_loss: 7.6330, val_acc: 0.5432\n",
      "Epoch [395], train_loss: 0.0001, val_loss: 7.6453, val_acc: 0.5339\n",
      "Epoch [396], train_loss: 0.0002, val_loss: 7.6766, val_acc: 0.5370\n",
      "Epoch [397], train_loss: 0.0001, val_loss: 7.6865, val_acc: 0.5323\n",
      "Epoch [398], train_loss: 0.0001, val_loss: 7.7060, val_acc: 0.5323\n",
      "Epoch [399], train_loss: 0.0001, val_loss: 7.7321, val_acc: 0.5354\n",
      "Epoch [400], train_loss: 0.0001, val_loss: 7.7387, val_acc: 0.5323\n",
      "Epoch [401], train_loss: 0.0001, val_loss: 7.7701, val_acc: 0.5323\n",
      "Epoch [402], train_loss: 0.0001, val_loss: 7.7793, val_acc: 0.5339\n",
      "Epoch [403], train_loss: 0.0001, val_loss: 7.8034, val_acc: 0.5339\n",
      "Epoch [404], train_loss: 0.0001, val_loss: 7.8280, val_acc: 0.5328\n",
      "Epoch [405], train_loss: 0.0001, val_loss: 7.8644, val_acc: 0.5375\n",
      "Epoch [406], train_loss: 0.0001, val_loss: 7.8616, val_acc: 0.5354\n",
      "Epoch [407], train_loss: 0.0001, val_loss: 7.8841, val_acc: 0.5354\n",
      "Epoch [408], train_loss: 0.0001, val_loss: 7.9211, val_acc: 0.5370\n",
      "Epoch [409], train_loss: 0.0001, val_loss: 7.9296, val_acc: 0.5344\n",
      "Epoch [410], train_loss: 0.0001, val_loss: 7.9709, val_acc: 0.5359\n",
      "Epoch [411], train_loss: 0.0001, val_loss: 7.9788, val_acc: 0.5339\n",
      "Epoch [412], train_loss: 0.0001, val_loss: 8.0025, val_acc: 0.5359\n",
      "Epoch [413], train_loss: 0.0001, val_loss: 8.0272, val_acc: 0.5359\n",
      "Epoch [414], train_loss: 0.0001, val_loss: 8.0353, val_acc: 0.5344\n",
      "Epoch [415], train_loss: 0.0001, val_loss: 8.0537, val_acc: 0.5370\n",
      "Epoch [416], train_loss: 0.0001, val_loss: 8.0730, val_acc: 0.5370\n",
      "Epoch [417], train_loss: 0.0001, val_loss: 8.1070, val_acc: 0.5370\n",
      "Epoch [418], train_loss: 0.0001, val_loss: 8.1090, val_acc: 0.5354\n",
      "Epoch [419], train_loss: 0.0001, val_loss: 8.1415, val_acc: 0.5328\n",
      "Epoch [420], train_loss: 0.0001, val_loss: 8.1500, val_acc: 0.5370\n",
      "Epoch [421], train_loss: 0.0001, val_loss: 8.1687, val_acc: 0.5339\n",
      "Epoch [422], train_loss: 0.0001, val_loss: 8.1913, val_acc: 0.5354\n",
      "Epoch [423], train_loss: 0.0001, val_loss: 8.2014, val_acc: 0.5370\n",
      "Epoch [424], train_loss: 0.0001, val_loss: 8.2627, val_acc: 0.5359\n",
      "Epoch [425], train_loss: 0.0001, val_loss: 8.2418, val_acc: 0.5339\n",
      "Epoch [426], train_loss: 0.0001, val_loss: 8.2736, val_acc: 0.5354\n",
      "Epoch [427], train_loss: 0.0001, val_loss: 8.2905, val_acc: 0.5354\n",
      "Epoch [428], train_loss: 0.0001, val_loss: 8.3048, val_acc: 0.5323\n",
      "Epoch [429], train_loss: 0.0001, val_loss: 8.3323, val_acc: 0.5339\n",
      "Epoch [430], train_loss: 0.0001, val_loss: 8.3550, val_acc: 0.5312\n",
      "Epoch [431], train_loss: 0.0001, val_loss: 8.3948, val_acc: 0.5375\n",
      "Epoch [432], train_loss: 0.0001, val_loss: 8.4002, val_acc: 0.5354\n",
      "Epoch [433], train_loss: 0.0000, val_loss: 8.4299, val_acc: 0.5375\n",
      "Epoch [434], train_loss: 0.0000, val_loss: 8.4354, val_acc: 0.5323\n",
      "Epoch [435], train_loss: 0.0001, val_loss: 8.4721, val_acc: 0.5297\n",
      "Epoch [436], train_loss: 0.0001, val_loss: 8.4752, val_acc: 0.5354\n",
      "Epoch [437], train_loss: 0.0000, val_loss: 8.4968, val_acc: 0.5370\n",
      "Epoch [438], train_loss: 0.0000, val_loss: 8.5121, val_acc: 0.5339\n",
      "Epoch [439], train_loss: 0.0000, val_loss: 8.5333, val_acc: 0.5307\n",
      "Epoch [440], train_loss: 0.0000, val_loss: 8.5561, val_acc: 0.5307\n",
      "Epoch [441], train_loss: 0.0000, val_loss: 8.5563, val_acc: 0.5323\n",
      "Epoch [442], train_loss: 0.0000, val_loss: 8.5997, val_acc: 0.5323\n",
      "Epoch [443], train_loss: 0.0000, val_loss: 8.6164, val_acc: 0.5354\n",
      "Epoch [444], train_loss: 0.0000, val_loss: 8.6390, val_acc: 0.5328\n",
      "Epoch [445], train_loss: 0.0000, val_loss: 8.6745, val_acc: 0.5359\n",
      "Epoch [446], train_loss: 0.0000, val_loss: 8.6715, val_acc: 0.5323\n",
      "Epoch [447], train_loss: 0.0000, val_loss: 8.6933, val_acc: 0.5307\n",
      "Epoch [448], train_loss: 0.0000, val_loss: 8.7329, val_acc: 0.5370\n",
      "Epoch [449], train_loss: 0.0000, val_loss: 8.7306, val_acc: 0.5307\n",
      "Epoch [450], train_loss: 0.0000, val_loss: 8.7705, val_acc: 0.5297\n",
      "Epoch [451], train_loss: 0.0000, val_loss: 8.7813, val_acc: 0.5339\n",
      "Epoch [452], train_loss: 0.0000, val_loss: 8.7991, val_acc: 0.5354\n",
      "Epoch [453], train_loss: 0.0000, val_loss: 8.8174, val_acc: 0.5323\n",
      "Epoch [454], train_loss: 0.0000, val_loss: 8.8439, val_acc: 0.5385\n",
      "Epoch [455], train_loss: 0.0000, val_loss: 8.8648, val_acc: 0.5370\n",
      "Epoch [456], train_loss: 0.0000, val_loss: 8.8843, val_acc: 0.5354\n",
      "Epoch [457], train_loss: 0.0000, val_loss: 8.9044, val_acc: 0.5344\n",
      "Epoch [458], train_loss: 0.0000, val_loss: 8.9250, val_acc: 0.5354\n",
      "Epoch [459], train_loss: 0.0000, val_loss: 8.9519, val_acc: 0.5339\n",
      "Epoch [460], train_loss: 0.0000, val_loss: 8.9584, val_acc: 0.5370\n",
      "Epoch [461], train_loss: 0.0000, val_loss: 9.0020, val_acc: 0.5375\n",
      "Epoch [462], train_loss: 0.0000, val_loss: 9.0255, val_acc: 0.5359\n",
      "Epoch [463], train_loss: 0.0000, val_loss: 9.0313, val_acc: 0.5307\n",
      "Epoch [464], train_loss: 0.0000, val_loss: 9.0471, val_acc: 0.5312\n",
      "Epoch [465], train_loss: 0.0000, val_loss: 9.0666, val_acc: 0.5339\n",
      "Epoch [466], train_loss: 0.0000, val_loss: 9.0841, val_acc: 0.5323\n",
      "Epoch [467], train_loss: 0.0000, val_loss: 9.1111, val_acc: 0.5323\n",
      "Epoch [468], train_loss: 0.0000, val_loss: 9.1304, val_acc: 0.5354\n",
      "Epoch [469], train_loss: 0.0000, val_loss: 9.1410, val_acc: 0.5323\n",
      "Epoch [470], train_loss: 0.0000, val_loss: 9.1599, val_acc: 0.5307\n",
      "Epoch [471], train_loss: 0.0000, val_loss: 9.1855, val_acc: 0.5323\n",
      "Epoch [472], train_loss: 0.0000, val_loss: 9.2245, val_acc: 0.5328\n",
      "Epoch [473], train_loss: 0.0000, val_loss: 9.2211, val_acc: 0.5339\n",
      "Epoch [474], train_loss: 0.0000, val_loss: 9.2449, val_acc: 0.5354\n",
      "Epoch [475], train_loss: 0.0000, val_loss: 9.2570, val_acc: 0.5354\n",
      "Epoch [476], train_loss: 0.0000, val_loss: 9.2947, val_acc: 0.5344\n",
      "Epoch [477], train_loss: 0.0000, val_loss: 9.3012, val_acc: 0.5339\n",
      "Epoch [478], train_loss: 0.0000, val_loss: 9.3229, val_acc: 0.5354\n",
      "Epoch [479], train_loss: 0.0000, val_loss: 9.3437, val_acc: 0.5339\n",
      "Epoch [480], train_loss: 0.0000, val_loss: 9.3547, val_acc: 0.5354\n",
      "Epoch [481], train_loss: 0.0000, val_loss: 9.3810, val_acc: 0.5339\n",
      "Epoch [482], train_loss: 0.0000, val_loss: 9.3959, val_acc: 0.5354\n",
      "Epoch [483], train_loss: 0.0000, val_loss: 9.4305, val_acc: 0.5370\n",
      "Epoch [484], train_loss: 0.0000, val_loss: 9.4509, val_acc: 0.5312\n",
      "Epoch [485], train_loss: 0.0000, val_loss: 9.4766, val_acc: 0.5328\n",
      "Epoch [486], train_loss: 0.0000, val_loss: 9.4983, val_acc: 0.5359\n",
      "Epoch [487], train_loss: 0.0000, val_loss: 9.5005, val_acc: 0.5312\n",
      "Epoch [488], train_loss: 0.0000, val_loss: 9.5177, val_acc: 0.5339\n",
      "Epoch [489], train_loss: 0.0000, val_loss: 9.5332, val_acc: 0.5339\n",
      "Epoch [490], train_loss: 0.0000, val_loss: 9.5537, val_acc: 0.5354\n",
      "Epoch [491], train_loss: 0.0000, val_loss: 9.5887, val_acc: 0.5354\n",
      "Epoch [492], train_loss: 0.0000, val_loss: 9.6053, val_acc: 0.5339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [493], train_loss: 0.0000, val_loss: 9.6236, val_acc: 0.5328\n",
      "Epoch [494], train_loss: 0.0000, val_loss: 9.6364, val_acc: 0.5354\n",
      "Epoch [495], train_loss: 0.0000, val_loss: 9.6694, val_acc: 0.5354\n",
      "Epoch [496], train_loss: 0.0000, val_loss: 9.6993, val_acc: 0.5328\n",
      "Epoch [497], train_loss: 0.0000, val_loss: 9.7193, val_acc: 0.5328\n",
      "Epoch [498], train_loss: 0.0000, val_loss: 9.7289, val_acc: 0.5312\n",
      "Epoch [499], train_loss: 0.0000, val_loss: 9.7347, val_acc: 0.5339\n",
      "Epoch [500], train_loss: 0.0000, val_loss: 9.7613, val_acc: 0.5323\n",
      "Epoch [501], train_loss: 0.0000, val_loss: 9.7842, val_acc: 0.5328\n",
      "Epoch [502], train_loss: 0.0000, val_loss: 9.8064, val_acc: 0.5281\n",
      "Epoch [503], train_loss: 0.0000, val_loss: 9.8116, val_acc: 0.5339\n",
      "Epoch [504], train_loss: 0.0000, val_loss: 9.8381, val_acc: 0.5354\n",
      "Epoch [505], train_loss: 0.0000, val_loss: 9.8639, val_acc: 0.5328\n",
      "Epoch [506], train_loss: 0.0000, val_loss: 9.8854, val_acc: 0.5328\n",
      "Epoch [507], train_loss: 0.0000, val_loss: 9.9022, val_acc: 0.5312\n",
      "Epoch [508], train_loss: 0.0000, val_loss: 9.9219, val_acc: 0.5339\n",
      "Epoch [509], train_loss: 0.0000, val_loss: 9.9353, val_acc: 0.5339\n",
      "Epoch [510], train_loss: 0.0000, val_loss: 9.9630, val_acc: 0.5297\n",
      "Epoch [511], train_loss: 0.0000, val_loss: 10.0130, val_acc: 0.5312\n",
      "Epoch [512], train_loss: 0.0000, val_loss: 9.9895, val_acc: 0.5292\n",
      "Epoch [513], train_loss: 0.0000, val_loss: 10.0236, val_acc: 0.5354\n",
      "Epoch [514], train_loss: 0.0000, val_loss: 10.0483, val_acc: 0.5323\n",
      "Epoch [515], train_loss: 0.0000, val_loss: 10.0601, val_acc: 0.5307\n",
      "Epoch [516], train_loss: 0.0000, val_loss: 10.0734, val_acc: 0.5307\n",
      "Epoch [517], train_loss: 0.0000, val_loss: 10.1037, val_acc: 0.5266\n",
      "Epoch [518], train_loss: 0.0000, val_loss: 10.1120, val_acc: 0.5339\n",
      "Epoch [519], train_loss: 0.0000, val_loss: 10.1374, val_acc: 0.5323\n",
      "Epoch [520], train_loss: 0.0000, val_loss: 10.1540, val_acc: 0.5297\n",
      "Epoch [521], train_loss: 0.0000, val_loss: 10.1850, val_acc: 0.5328\n",
      "Epoch [522], train_loss: 0.0000, val_loss: 10.2103, val_acc: 0.5375\n",
      "Epoch [523], train_loss: 0.0000, val_loss: 10.2187, val_acc: 0.5328\n",
      "Epoch [524], train_loss: 0.0000, val_loss: 10.2352, val_acc: 0.5328\n",
      "Epoch [525], train_loss: 0.0000, val_loss: 10.2462, val_acc: 0.5354\n",
      "Epoch [526], train_loss: 0.0000, val_loss: 10.2552, val_acc: 0.5281\n",
      "Epoch [527], train_loss: 0.0000, val_loss: 10.2769, val_acc: 0.5323\n",
      "Epoch [528], train_loss: 0.0000, val_loss: 10.3287, val_acc: 0.5328\n",
      "Epoch [529], train_loss: 0.0000, val_loss: 10.3169, val_acc: 0.5307\n",
      "Epoch [530], train_loss: 0.0000, val_loss: 10.3492, val_acc: 0.5323\n",
      "Epoch [531], train_loss: 0.0000, val_loss: 10.3581, val_acc: 0.5323\n",
      "Epoch [532], train_loss: 0.0000, val_loss: 10.3889, val_acc: 0.5323\n",
      "Epoch [533], train_loss: 0.0000, val_loss: 10.4105, val_acc: 0.5281\n",
      "Epoch [534], train_loss: 0.0000, val_loss: 10.4355, val_acc: 0.5297\n",
      "Epoch [535], train_loss: 0.0000, val_loss: 10.4373, val_acc: 0.5323\n",
      "Epoch [536], train_loss: 0.0000, val_loss: 10.4405, val_acc: 0.5339\n",
      "Epoch [537], train_loss: 0.0000, val_loss: 10.4754, val_acc: 0.5323\n",
      "Epoch [538], train_loss: 0.0000, val_loss: 10.4997, val_acc: 0.5266\n",
      "Epoch [539], train_loss: 0.0000, val_loss: 10.4998, val_acc: 0.5292\n",
      "Epoch [540], train_loss: 0.0000, val_loss: 10.5449, val_acc: 0.5312\n",
      "Epoch [541], train_loss: 0.0000, val_loss: 10.5597, val_acc: 0.5297\n",
      "Epoch [542], train_loss: 0.0000, val_loss: 10.5795, val_acc: 0.5297\n",
      "Epoch [543], train_loss: 0.0000, val_loss: 10.6014, val_acc: 0.5297\n",
      "Epoch [544], train_loss: 0.0000, val_loss: 10.6096, val_acc: 0.5323\n",
      "Epoch [545], train_loss: 0.0000, val_loss: 10.6294, val_acc: 0.5323\n",
      "Epoch [546], train_loss: 0.0000, val_loss: 10.6441, val_acc: 0.5307\n",
      "Epoch [547], train_loss: 0.0000, val_loss: 10.6662, val_acc: 0.5323\n",
      "Epoch [548], train_loss: 0.0000, val_loss: 10.6848, val_acc: 0.5307\n",
      "Epoch [549], train_loss: 0.0000, val_loss: 10.6989, val_acc: 0.5354\n",
      "Epoch [550], train_loss: 0.0000, val_loss: 10.7460, val_acc: 0.5344\n",
      "Epoch [551], train_loss: 0.0000, val_loss: 10.7320, val_acc: 0.5323\n",
      "Epoch [552], train_loss: 0.0000, val_loss: 10.7592, val_acc: 0.5307\n",
      "Epoch [553], train_loss: 0.0000, val_loss: 10.7740, val_acc: 0.5281\n",
      "Epoch [554], train_loss: 0.0000, val_loss: 10.7886, val_acc: 0.5323\n",
      "Epoch [555], train_loss: 0.0000, val_loss: 10.8209, val_acc: 0.5281\n",
      "Epoch [556], train_loss: 0.0000, val_loss: 10.8411, val_acc: 0.5344\n",
      "Epoch [557], train_loss: 0.0000, val_loss: 10.8579, val_acc: 0.5323\n",
      "Epoch [558], train_loss: 0.0000, val_loss: 10.8675, val_acc: 0.5323\n",
      "Epoch [559], train_loss: 0.0000, val_loss: 10.8791, val_acc: 0.5339\n",
      "Epoch [560], train_loss: 0.0000, val_loss: 10.9216, val_acc: 0.5297\n",
      "Epoch [561], train_loss: 0.0000, val_loss: 10.9377, val_acc: 0.5297\n",
      "Epoch [562], train_loss: 0.0000, val_loss: 10.9476, val_acc: 0.5339\n",
      "Epoch [563], train_loss: 0.0000, val_loss: 10.9702, val_acc: 0.5281\n",
      "Epoch [564], train_loss: 0.0000, val_loss: 10.9926, val_acc: 0.5281\n",
      "Epoch [565], train_loss: 0.0000, val_loss: 11.0081, val_acc: 0.5281\n",
      "Epoch [566], train_loss: 0.0000, val_loss: 11.0142, val_acc: 0.5307\n",
      "Epoch [567], train_loss: 0.0000, val_loss: 11.0512, val_acc: 0.5328\n",
      "Epoch [568], train_loss: 0.0000, val_loss: 11.0535, val_acc: 0.5281\n",
      "Epoch [569], train_loss: 0.0000, val_loss: 11.0770, val_acc: 0.5323\n",
      "Epoch [570], train_loss: 0.0000, val_loss: 11.1164, val_acc: 0.5344\n",
      "Epoch [571], train_loss: 0.0000, val_loss: 11.1077, val_acc: 0.5292\n",
      "Epoch [572], train_loss: 0.0000, val_loss: 11.1343, val_acc: 0.5297\n",
      "Epoch [573], train_loss: 0.0000, val_loss: 11.1646, val_acc: 0.5281\n",
      "Epoch [574], train_loss: 0.0000, val_loss: 11.1909, val_acc: 0.5328\n",
      "Epoch [575], train_loss: 0.0000, val_loss: 11.1900, val_acc: 0.5297\n",
      "Epoch [576], train_loss: 0.0000, val_loss: 11.2172, val_acc: 0.5281\n",
      "Epoch [577], train_loss: 0.0000, val_loss: 11.2306, val_acc: 0.5312\n",
      "Epoch [578], train_loss: 0.0000, val_loss: 11.2592, val_acc: 0.5281\n",
      "Epoch [579], train_loss: 0.0000, val_loss: 11.2575, val_acc: 0.5307\n",
      "Epoch [580], train_loss: 0.0000, val_loss: 11.2836, val_acc: 0.5297\n",
      "Epoch [581], train_loss: 0.0000, val_loss: 11.3043, val_acc: 0.5307\n",
      "Epoch [582], train_loss: 0.0000, val_loss: 11.3287, val_acc: 0.5297\n",
      "Epoch [583], train_loss: 0.0000, val_loss: 11.3342, val_acc: 0.5281\n",
      "Epoch [584], train_loss: 0.0000, val_loss: 11.3431, val_acc: 0.5307\n",
      "Epoch [585], train_loss: 0.0000, val_loss: 11.3700, val_acc: 0.5307\n",
      "Epoch [586], train_loss: 0.0000, val_loss: 11.3894, val_acc: 0.5307\n",
      "Epoch [587], train_loss: 0.0000, val_loss: 11.4027, val_acc: 0.5323\n",
      "Epoch [588], train_loss: 0.0000, val_loss: 11.4324, val_acc: 0.5281\n",
      "Epoch [589], train_loss: 0.0000, val_loss: 11.4441, val_acc: 0.5312\n",
      "Epoch [590], train_loss: 0.0000, val_loss: 11.4633, val_acc: 0.5307\n",
      "Epoch [591], train_loss: 0.0000, val_loss: 11.4984, val_acc: 0.5281\n",
      "Epoch [592], train_loss: 0.0000, val_loss: 11.5077, val_acc: 0.5250\n",
      "Epoch [593], train_loss: 0.0000, val_loss: 11.5271, val_acc: 0.5385\n",
      "Epoch [594], train_loss: 0.0000, val_loss: 11.5409, val_acc: 0.5307\n",
      "Epoch [595], train_loss: 0.0000, val_loss: 11.5532, val_acc: 0.5323\n",
      "Epoch [596], train_loss: 0.0000, val_loss: 11.5763, val_acc: 0.5266\n",
      "Epoch [597], train_loss: 0.0000, val_loss: 11.5899, val_acc: 0.5307\n",
      "Epoch [598], train_loss: 0.0000, val_loss: 11.6194, val_acc: 0.5297\n",
      "Epoch [599], train_loss: 0.0000, val_loss: 11.6475, val_acc: 0.5250\n",
      "Epoch [600], train_loss: 0.0000, val_loss: 11.6530, val_acc: 0.5307\n",
      "Epoch [601], train_loss: 0.0000, val_loss: 11.6680, val_acc: 0.5266\n",
      "Epoch [602], train_loss: 0.0000, val_loss: 11.6963, val_acc: 0.5297\n",
      "Epoch [603], train_loss: 0.0000, val_loss: 11.7188, val_acc: 0.5281\n",
      "Epoch [604], train_loss: 0.0000, val_loss: 11.7230, val_acc: 0.5307\n",
      "Epoch [605], train_loss: 0.0000, val_loss: 11.7402, val_acc: 0.5250\n",
      "Epoch [606], train_loss: 0.0000, val_loss: 11.7698, val_acc: 0.5281\n",
      "Epoch [607], train_loss: 0.0000, val_loss: 11.7759, val_acc: 0.5339\n",
      "Epoch [608], train_loss: 0.0000, val_loss: 11.7972, val_acc: 0.5312\n",
      "Epoch [609], train_loss: 0.0000, val_loss: 11.8128, val_acc: 0.5307\n",
      "Epoch [610], train_loss: 0.0000, val_loss: 11.8211, val_acc: 0.5281\n",
      "Epoch [611], train_loss: 0.0000, val_loss: 11.8590, val_acc: 0.5312\n",
      "Epoch [612], train_loss: 0.0000, val_loss: 11.8764, val_acc: 0.5266\n",
      "Epoch [613], train_loss: 0.0000, val_loss: 11.8955, val_acc: 0.5266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [614], train_loss: 0.0000, val_loss: 11.8935, val_acc: 0.5323\n",
      "Epoch [615], train_loss: 0.0000, val_loss: 11.9371, val_acc: 0.5250\n",
      "Epoch [616], train_loss: 0.0000, val_loss: 11.9371, val_acc: 0.5339\n",
      "Epoch [617], train_loss: 0.0000, val_loss: 11.9521, val_acc: 0.5292\n",
      "Epoch [618], train_loss: 0.0000, val_loss: 11.9668, val_acc: 0.5307\n",
      "Epoch [619], train_loss: 0.0000, val_loss: 11.9838, val_acc: 0.5281\n",
      "Epoch [620], train_loss: 0.0000, val_loss: 12.0065, val_acc: 0.5281\n",
      "Epoch [621], train_loss: 0.0000, val_loss: 12.0127, val_acc: 0.5323\n",
      "Epoch [622], train_loss: 0.0000, val_loss: 12.0328, val_acc: 0.5307\n",
      "Epoch [623], train_loss: 0.0000, val_loss: 12.0582, val_acc: 0.5297\n",
      "Epoch [624], train_loss: 0.0000, val_loss: 12.0790, val_acc: 0.5307\n",
      "Epoch [625], train_loss: 0.0000, val_loss: 12.0872, val_acc: 0.5276\n",
      "Epoch [626], train_loss: 0.0000, val_loss: 12.1297, val_acc: 0.5281\n",
      "Epoch [627], train_loss: 0.0000, val_loss: 12.1485, val_acc: 0.5266\n",
      "Epoch [628], train_loss: 0.0000, val_loss: 12.1642, val_acc: 0.5281\n",
      "Epoch [629], train_loss: 0.0000, val_loss: 12.1693, val_acc: 0.5281\n",
      "Epoch [630], train_loss: 0.0000, val_loss: 12.1930, val_acc: 0.5297\n",
      "Epoch [631], train_loss: 0.0000, val_loss: 12.2034, val_acc: 0.5266\n",
      "Epoch [632], train_loss: 0.0000, val_loss: 12.2199, val_acc: 0.5281\n",
      "Epoch [633], train_loss: 0.0000, val_loss: 12.2312, val_acc: 0.5307\n",
      "Epoch [634], train_loss: 0.0000, val_loss: 12.2626, val_acc: 0.5297\n",
      "Epoch [635], train_loss: 0.0000, val_loss: 12.2640, val_acc: 0.5266\n",
      "Epoch [636], train_loss: 0.0000, val_loss: 12.2864, val_acc: 0.5266\n",
      "Epoch [637], train_loss: 0.0000, val_loss: 12.3217, val_acc: 0.5266\n",
      "Epoch [638], train_loss: 0.0000, val_loss: 12.3280, val_acc: 0.5323\n",
      "Epoch [639], train_loss: 0.0000, val_loss: 12.3494, val_acc: 0.5323\n",
      "Epoch [640], train_loss: 0.0000, val_loss: 12.3616, val_acc: 0.5323\n",
      "Epoch [641], train_loss: 0.0000, val_loss: 12.3746, val_acc: 0.5292\n",
      "Epoch [642], train_loss: 0.0000, val_loss: 12.3926, val_acc: 0.5266\n",
      "Epoch [643], train_loss: 0.0000, val_loss: 12.4297, val_acc: 0.5281\n",
      "Epoch [644], train_loss: 0.0000, val_loss: 12.4373, val_acc: 0.5266\n",
      "Epoch [645], train_loss: 0.0000, val_loss: 12.4399, val_acc: 0.5276\n",
      "Epoch [646], train_loss: 0.0000, val_loss: 12.4633, val_acc: 0.5339\n",
      "Epoch [647], train_loss: 0.0000, val_loss: 12.4887, val_acc: 0.5266\n",
      "Epoch [648], train_loss: 0.0000, val_loss: 12.5010, val_acc: 0.5281\n",
      "Epoch [649], train_loss: 0.0000, val_loss: 12.5301, val_acc: 0.5297\n",
      "Epoch [650], train_loss: 0.0000, val_loss: 12.5302, val_acc: 0.5323\n",
      "Epoch [651], train_loss: 0.0000, val_loss: 12.5551, val_acc: 0.5266\n",
      "Epoch [652], train_loss: 0.0000, val_loss: 12.5806, val_acc: 0.5281\n",
      "Epoch [653], train_loss: 0.0000, val_loss: 12.5863, val_acc: 0.5266\n",
      "Epoch [654], train_loss: 0.0000, val_loss: 12.6140, val_acc: 0.5266\n",
      "Epoch [655], train_loss: 0.0000, val_loss: 12.6153, val_acc: 0.5292\n",
      "Epoch [656], train_loss: 0.0000, val_loss: 12.6509, val_acc: 0.5281\n",
      "Epoch [657], train_loss: 0.0000, val_loss: 12.6640, val_acc: 0.5307\n",
      "Epoch [658], train_loss: 0.0000, val_loss: 12.6831, val_acc: 0.5281\n",
      "Epoch [659], train_loss: 0.0000, val_loss: 12.7095, val_acc: 0.5328\n",
      "Epoch [660], train_loss: 0.0000, val_loss: 12.7093, val_acc: 0.5266\n",
      "Epoch [661], train_loss: 0.0000, val_loss: 12.7296, val_acc: 0.5307\n",
      "Epoch [662], train_loss: 0.0000, val_loss: 12.7486, val_acc: 0.5281\n",
      "Epoch [663], train_loss: 0.0000, val_loss: 12.7842, val_acc: 0.5312\n",
      "Epoch [664], train_loss: 0.0000, val_loss: 12.7841, val_acc: 0.5307\n",
      "Epoch [665], train_loss: 0.0000, val_loss: 12.8081, val_acc: 0.5266\n",
      "Epoch [666], train_loss: 0.0000, val_loss: 12.8220, val_acc: 0.5297\n",
      "Epoch [667], train_loss: 0.0000, val_loss: 12.8492, val_acc: 0.5281\n",
      "Epoch [668], train_loss: 0.0000, val_loss: 12.8644, val_acc: 0.5266\n",
      "Epoch [669], train_loss: 0.0000, val_loss: 12.8648, val_acc: 0.5276\n",
      "Epoch [670], train_loss: 0.0000, val_loss: 12.8928, val_acc: 0.5266\n",
      "Epoch [671], train_loss: 0.0000, val_loss: 12.9231, val_acc: 0.5297\n",
      "Epoch [672], train_loss: 0.0000, val_loss: 12.9304, val_acc: 0.5266\n",
      "Epoch [673], train_loss: 0.0000, val_loss: 12.9423, val_acc: 0.5297\n",
      "Epoch [674], train_loss: 0.0000, val_loss: 12.9621, val_acc: 0.5266\n",
      "Epoch [675], train_loss: 0.0000, val_loss: 12.9842, val_acc: 0.5281\n",
      "Epoch [676], train_loss: 0.0000, val_loss: 12.9860, val_acc: 0.5323\n",
      "Epoch [677], train_loss: 0.0000, val_loss: 12.9969, val_acc: 0.5307\n",
      "Epoch [678], train_loss: 0.0000, val_loss: 13.0341, val_acc: 0.5281\n",
      "Epoch [679], train_loss: 0.0000, val_loss: 13.0431, val_acc: 0.5266\n",
      "Epoch [680], train_loss: 0.0000, val_loss: 13.0450, val_acc: 0.5307\n",
      "Epoch [681], train_loss: 0.0000, val_loss: 13.0728, val_acc: 0.5266\n",
      "Epoch [682], train_loss: 0.0000, val_loss: 13.0907, val_acc: 0.5266\n",
      "Epoch [683], train_loss: 0.0000, val_loss: 13.0969, val_acc: 0.5307\n",
      "Epoch [684], train_loss: 0.0000, val_loss: 13.1128, val_acc: 0.5307\n",
      "Epoch [685], train_loss: 0.0000, val_loss: 13.1275, val_acc: 0.5307\n",
      "Epoch [686], train_loss: 0.0000, val_loss: 13.1533, val_acc: 0.5323\n",
      "Epoch [687], train_loss: 0.0000, val_loss: 13.1756, val_acc: 0.5281\n",
      "Epoch [688], train_loss: 0.0000, val_loss: 13.1760, val_acc: 0.5292\n",
      "Epoch [689], train_loss: 0.0000, val_loss: 13.2132, val_acc: 0.5297\n",
      "Epoch [690], train_loss: 0.0000, val_loss: 13.2198, val_acc: 0.5281\n",
      "Epoch [691], train_loss: 0.0000, val_loss: 13.2451, val_acc: 0.5281\n",
      "Epoch [692], train_loss: 0.0000, val_loss: 13.2580, val_acc: 0.5281\n",
      "Epoch [693], train_loss: 0.0000, val_loss: 13.2616, val_acc: 0.5292\n",
      "Epoch [694], train_loss: 0.0000, val_loss: 13.2790, val_acc: 0.5276\n",
      "Epoch [695], train_loss: 0.0000, val_loss: 13.3139, val_acc: 0.5297\n",
      "Epoch [696], train_loss: 0.0000, val_loss: 13.3269, val_acc: 0.5297\n",
      "Epoch [697], train_loss: 0.0000, val_loss: 13.3417, val_acc: 0.5297\n",
      "Epoch [698], train_loss: 0.0000, val_loss: 13.3558, val_acc: 0.5307\n",
      "Epoch [699], train_loss: 0.0000, val_loss: 13.3679, val_acc: 0.5307\n",
      "Epoch [700], train_loss: 0.0000, val_loss: 13.3899, val_acc: 0.5266\n",
      "Epoch [701], train_loss: 0.0000, val_loss: 13.4012, val_acc: 0.5297\n",
      "Epoch [702], train_loss: 0.0000, val_loss: 13.4241, val_acc: 0.5312\n",
      "Epoch [703], train_loss: 0.0000, val_loss: 13.4309, val_acc: 0.5312\n",
      "Epoch [704], train_loss: 0.0000, val_loss: 13.4585, val_acc: 0.5281\n",
      "Epoch [705], train_loss: 0.0000, val_loss: 13.4491, val_acc: 0.5281\n",
      "Epoch [706], train_loss: 0.0000, val_loss: 13.4763, val_acc: 0.5307\n",
      "Epoch [707], train_loss: 0.0000, val_loss: 13.4829, val_acc: 0.5307\n",
      "Epoch [708], train_loss: 0.0000, val_loss: 13.5025, val_acc: 0.5307\n",
      "Epoch [709], train_loss: 0.0000, val_loss: 13.5295, val_acc: 0.5281\n",
      "Epoch [710], train_loss: 0.0000, val_loss: 13.5360, val_acc: 0.5307\n",
      "Epoch [711], train_loss: 0.0000, val_loss: 13.5632, val_acc: 0.5281\n",
      "Epoch [712], train_loss: 0.0000, val_loss: 13.5850, val_acc: 0.5312\n",
      "Epoch [713], train_loss: 0.0000, val_loss: 13.6034, val_acc: 0.5297\n",
      "Epoch [714], train_loss: 0.0000, val_loss: 13.6114, val_acc: 0.5312\n",
      "Epoch [715], train_loss: 0.0000, val_loss: 13.6255, val_acc: 0.5281\n",
      "Epoch [716], train_loss: 0.0000, val_loss: 13.6457, val_acc: 0.5297\n",
      "Epoch [717], train_loss: 0.0000, val_loss: 13.6620, val_acc: 0.5312\n",
      "Epoch [718], train_loss: 0.0000, val_loss: 13.6627, val_acc: 0.5266\n",
      "Epoch [719], train_loss: 0.0000, val_loss: 13.6933, val_acc: 0.5250\n",
      "Epoch [720], train_loss: 0.0000, val_loss: 13.7009, val_acc: 0.5266\n",
      "Epoch [721], train_loss: 0.0000, val_loss: 13.7196, val_acc: 0.5281\n",
      "Epoch [722], train_loss: 0.0000, val_loss: 13.7364, val_acc: 0.5297\n",
      "Epoch [723], train_loss: 0.0000, val_loss: 13.7616, val_acc: 0.5297\n",
      "Epoch [724], train_loss: 0.0000, val_loss: 13.7736, val_acc: 0.5297\n",
      "Epoch [725], train_loss: 0.0000, val_loss: 13.7782, val_acc: 0.5292\n",
      "Epoch [726], train_loss: 0.0000, val_loss: 13.8024, val_acc: 0.5250\n",
      "Epoch [727], train_loss: 0.0000, val_loss: 13.8107, val_acc: 0.5312\n",
      "Epoch [728], train_loss: 0.0000, val_loss: 13.8224, val_acc: 0.5292\n",
      "Epoch [729], train_loss: 0.0000, val_loss: 13.8433, val_acc: 0.5297\n",
      "Epoch [730], train_loss: 0.0000, val_loss: 13.8598, val_acc: 0.5297\n",
      "Epoch [731], train_loss: 0.0000, val_loss: 13.8683, val_acc: 0.5307\n",
      "Epoch [732], train_loss: 0.0000, val_loss: 13.8899, val_acc: 0.5266\n",
      "Epoch [733], train_loss: 0.0000, val_loss: 13.8961, val_acc: 0.5323\n",
      "Epoch [734], train_loss: 0.0000, val_loss: 13.9218, val_acc: 0.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [735], train_loss: 0.0000, val_loss: 13.9386, val_acc: 0.5297\n",
      "Epoch [736], train_loss: 0.0000, val_loss: 13.9434, val_acc: 0.5312\n",
      "Epoch [737], train_loss: 0.0000, val_loss: 13.9641, val_acc: 0.5281\n",
      "Epoch [738], train_loss: 0.0000, val_loss: 13.9837, val_acc: 0.5312\n",
      "Epoch [739], train_loss: 0.0000, val_loss: 13.9896, val_acc: 0.5312\n",
      "Epoch [740], train_loss: 0.0000, val_loss: 14.0079, val_acc: 0.5281\n",
      "Epoch [741], train_loss: 0.0000, val_loss: 14.0148, val_acc: 0.5292\n",
      "Epoch [742], train_loss: 0.0000, val_loss: 14.0347, val_acc: 0.5266\n",
      "Epoch [743], train_loss: 0.0000, val_loss: 14.0492, val_acc: 0.5328\n",
      "Epoch [744], train_loss: 0.0000, val_loss: 14.0594, val_acc: 0.5297\n",
      "Epoch [745], train_loss: 0.0000, val_loss: 14.0772, val_acc: 0.5266\n",
      "Epoch [746], train_loss: 0.0000, val_loss: 14.1010, val_acc: 0.5297\n",
      "Epoch [747], train_loss: 0.0000, val_loss: 14.1078, val_acc: 0.5297\n",
      "Epoch [748], train_loss: 0.0000, val_loss: 14.1215, val_acc: 0.5266\n",
      "Epoch [749], train_loss: 0.0000, val_loss: 14.1340, val_acc: 0.5292\n",
      "Epoch [750], train_loss: 0.0000, val_loss: 14.1678, val_acc: 0.5312\n",
      "Epoch [751], train_loss: 0.0000, val_loss: 14.1784, val_acc: 0.5297\n",
      "Epoch [752], train_loss: 0.0000, val_loss: 14.1965, val_acc: 0.5297\n",
      "Epoch [753], train_loss: 0.0000, val_loss: 14.2059, val_acc: 0.5297\n",
      "Epoch [754], train_loss: 0.0000, val_loss: 14.2204, val_acc: 0.5281\n",
      "Epoch [755], train_loss: 0.0000, val_loss: 14.2274, val_acc: 0.5297\n",
      "Epoch [756], train_loss: 0.0000, val_loss: 14.2426, val_acc: 0.5297\n",
      "Epoch [757], train_loss: 0.0000, val_loss: 14.2703, val_acc: 0.5297\n",
      "Epoch [758], train_loss: 0.0000, val_loss: 14.2798, val_acc: 0.5297\n",
      "Epoch [759], train_loss: 0.0000, val_loss: 14.3000, val_acc: 0.5297\n",
      "Epoch [760], train_loss: 0.0000, val_loss: 14.3075, val_acc: 0.5266\n",
      "Epoch [761], train_loss: 0.0000, val_loss: 14.3151, val_acc: 0.5276\n",
      "Epoch [762], train_loss: 0.0000, val_loss: 14.3450, val_acc: 0.5266\n",
      "Epoch [763], train_loss: 0.0000, val_loss: 14.3469, val_acc: 0.5292\n",
      "Epoch [764], train_loss: 0.0000, val_loss: 14.3742, val_acc: 0.5297\n",
      "Epoch [765], train_loss: 0.0000, val_loss: 14.3810, val_acc: 0.5297\n",
      "Epoch [766], train_loss: 0.0000, val_loss: 14.4131, val_acc: 0.5297\n",
      "Epoch [767], train_loss: 0.0000, val_loss: 14.4141, val_acc: 0.5281\n",
      "Epoch [768], train_loss: 0.0000, val_loss: 14.4275, val_acc: 0.5266\n",
      "Epoch [769], train_loss: 0.0000, val_loss: 14.4476, val_acc: 0.5297\n",
      "Epoch [770], train_loss: 0.0000, val_loss: 14.4611, val_acc: 0.5281\n",
      "Epoch [771], train_loss: 0.0000, val_loss: 14.4861, val_acc: 0.5297\n",
      "Epoch [772], train_loss: 0.0000, val_loss: 14.5135, val_acc: 0.5328\n",
      "Epoch [773], train_loss: 0.0000, val_loss: 14.5188, val_acc: 0.5297\n",
      "Epoch [774], train_loss: 0.0000, val_loss: 14.5330, val_acc: 0.5266\n",
      "Epoch [775], train_loss: 0.0000, val_loss: 14.5552, val_acc: 0.5281\n",
      "Epoch [776], train_loss: 0.0000, val_loss: 14.5567, val_acc: 0.5276\n",
      "Epoch [777], train_loss: 0.0000, val_loss: 14.5891, val_acc: 0.5297\n",
      "Epoch [778], train_loss: 0.0000, val_loss: 14.5966, val_acc: 0.5281\n",
      "Epoch [779], train_loss: 0.0000, val_loss: 14.6182, val_acc: 0.5250\n",
      "Epoch [780], train_loss: 0.0000, val_loss: 14.6461, val_acc: 0.5312\n",
      "Epoch [781], train_loss: 0.0000, val_loss: 14.6532, val_acc: 0.5281\n",
      "Epoch [782], train_loss: 0.0000, val_loss: 14.6715, val_acc: 0.5276\n",
      "Epoch [783], train_loss: 0.0000, val_loss: 14.6989, val_acc: 0.5281\n",
      "Epoch [784], train_loss: 0.0000, val_loss: 14.7151, val_acc: 0.5250\n",
      "Epoch [785], train_loss: 0.0000, val_loss: 14.7379, val_acc: 0.5297\n",
      "Epoch [786], train_loss: 0.0000, val_loss: 14.7464, val_acc: 0.5266\n",
      "Epoch [787], train_loss: 0.0000, val_loss: 14.7698, val_acc: 0.5297\n",
      "Epoch [788], train_loss: 0.0000, val_loss: 14.7855, val_acc: 0.5266\n",
      "Epoch [789], train_loss: 0.0000, val_loss: 14.8104, val_acc: 0.5312\n",
      "Epoch [790], train_loss: 0.0000, val_loss: 14.8350, val_acc: 0.5312\n",
      "Epoch [791], train_loss: 0.0000, val_loss: 14.8549, val_acc: 0.5266\n",
      "Epoch [792], train_loss: 0.0000, val_loss: 14.8771, val_acc: 0.5328\n",
      "Epoch [793], train_loss: 0.0000, val_loss: 14.8999, val_acc: 0.5344\n",
      "Epoch [794], train_loss: 0.0000, val_loss: 14.9077, val_acc: 0.5328\n",
      "Epoch [795], train_loss: 0.0000, val_loss: 14.9439, val_acc: 0.5328\n",
      "Epoch [796], train_loss: 0.0000, val_loss: 14.9612, val_acc: 0.5297\n",
      "Epoch [797], train_loss: 0.0000, val_loss: 14.9921, val_acc: 0.5344\n",
      "Epoch [798], train_loss: 0.0000, val_loss: 14.9946, val_acc: 0.5297\n",
      "Epoch [799], train_loss: 0.0000, val_loss: 15.0416, val_acc: 0.5328\n",
      "Epoch [800], train_loss: 0.0000, val_loss: 15.0448, val_acc: 0.5344\n",
      "Epoch [801], train_loss: 0.0000, val_loss: 15.0827, val_acc: 0.5312\n",
      "Epoch [802], train_loss: 0.0000, val_loss: 15.1059, val_acc: 0.5359\n",
      "Epoch [803], train_loss: 0.0000, val_loss: 15.1275, val_acc: 0.5312\n",
      "Epoch [804], train_loss: 0.0000, val_loss: 15.1847, val_acc: 0.5312\n",
      "Epoch [805], train_loss: 0.0000, val_loss: 15.2122, val_acc: 0.5359\n",
      "Epoch [806], train_loss: 0.0000, val_loss: 15.2250, val_acc: 0.5344\n",
      "Epoch [807], train_loss: 0.0000, val_loss: 15.2586, val_acc: 0.5359\n",
      "Epoch [808], train_loss: 0.0000, val_loss: 15.2761, val_acc: 0.5312\n",
      "Epoch [809], train_loss: 0.0000, val_loss: 15.3096, val_acc: 0.5344\n",
      "Epoch [810], train_loss: 0.0000, val_loss: 15.3460, val_acc: 0.5328\n",
      "Epoch [811], train_loss: 0.5956, val_loss: 22.5662, val_acc: 0.4995\n",
      "Epoch [812], train_loss: 0.8956, val_loss: 13.5868, val_acc: 0.5344\n",
      "Epoch [813], train_loss: 0.2215, val_loss: 13.8358, val_acc: 0.5448\n",
      "Epoch [814], train_loss: 0.0261, val_loss: 13.0268, val_acc: 0.5469\n",
      "Epoch [815], train_loss: 0.0331, val_loss: 13.3575, val_acc: 0.5542\n",
      "Epoch [816], train_loss: 0.0221, val_loss: 12.8820, val_acc: 0.5401\n",
      "Epoch [817], train_loss: 0.0006, val_loss: 12.8370, val_acc: 0.5458\n",
      "Epoch [818], train_loss: 0.0001, val_loss: 12.8515, val_acc: 0.5432\n",
      "Epoch [819], train_loss: 0.0001, val_loss: 12.8507, val_acc: 0.5432\n",
      "Epoch [820], train_loss: 0.0001, val_loss: 12.8521, val_acc: 0.5464\n",
      "Epoch [821], train_loss: 0.0001, val_loss: 12.8490, val_acc: 0.5464\n",
      "Epoch [822], train_loss: 0.0001, val_loss: 12.8465, val_acc: 0.5448\n",
      "Epoch [823], train_loss: 0.0000, val_loss: 12.8447, val_acc: 0.5464\n",
      "Epoch [824], train_loss: 0.0000, val_loss: 12.8437, val_acc: 0.5464\n",
      "Epoch [825], train_loss: 0.0000, val_loss: 12.8423, val_acc: 0.5464\n",
      "Epoch [826], train_loss: 0.0000, val_loss: 12.8408, val_acc: 0.5464\n",
      "Epoch [827], train_loss: 0.0000, val_loss: 12.8392, val_acc: 0.5505\n",
      "Epoch [828], train_loss: 0.0000, val_loss: 12.8384, val_acc: 0.5521\n",
      "Epoch [829], train_loss: 0.0000, val_loss: 12.8371, val_acc: 0.5521\n",
      "Epoch [830], train_loss: 0.0000, val_loss: 12.8370, val_acc: 0.5505\n",
      "Epoch [831], train_loss: 0.0000, val_loss: 12.8359, val_acc: 0.5474\n",
      "Epoch [832], train_loss: 0.0000, val_loss: 12.8348, val_acc: 0.5474\n",
      "Epoch [833], train_loss: 0.0000, val_loss: 12.8332, val_acc: 0.5490\n",
      "Epoch [834], train_loss: 0.0000, val_loss: 12.8339, val_acc: 0.5458\n",
      "Epoch [835], train_loss: 0.0000, val_loss: 12.8330, val_acc: 0.5458\n",
      "Epoch [836], train_loss: 0.0000, val_loss: 12.8328, val_acc: 0.5458\n",
      "Epoch [837], train_loss: 0.0000, val_loss: 12.8322, val_acc: 0.5458\n",
      "Epoch [838], train_loss: 0.0000, val_loss: 12.8314, val_acc: 0.5458\n",
      "Epoch [839], train_loss: 0.0000, val_loss: 12.8307, val_acc: 0.5458\n",
      "Epoch [840], train_loss: 0.0000, val_loss: 12.8304, val_acc: 0.5474\n",
      "Epoch [841], train_loss: 0.0000, val_loss: 12.8310, val_acc: 0.5474\n",
      "Epoch [842], train_loss: 0.0000, val_loss: 12.8295, val_acc: 0.5490\n",
      "Epoch [843], train_loss: 0.0000, val_loss: 12.8293, val_acc: 0.5474\n",
      "Epoch [844], train_loss: 0.0000, val_loss: 12.8294, val_acc: 0.5474\n",
      "Epoch [845], train_loss: 0.0000, val_loss: 12.8286, val_acc: 0.5474\n",
      "Epoch [846], train_loss: 0.0000, val_loss: 12.8286, val_acc: 0.5474\n",
      "Epoch [847], train_loss: 0.0000, val_loss: 12.8286, val_acc: 0.5474\n",
      "Epoch [848], train_loss: 0.0000, val_loss: 12.8284, val_acc: 0.5474\n",
      "Epoch [849], train_loss: 0.0000, val_loss: 12.8282, val_acc: 0.5474\n",
      "Epoch [850], train_loss: 0.0000, val_loss: 12.8276, val_acc: 0.5474\n",
      "Epoch [851], train_loss: 0.0000, val_loss: 12.8279, val_acc: 0.5474\n",
      "Epoch [852], train_loss: 0.0000, val_loss: 12.8276, val_acc: 0.5474\n",
      "Epoch [853], train_loss: 0.0000, val_loss: 12.8278, val_acc: 0.5474\n",
      "Epoch [854], train_loss: 0.0000, val_loss: 12.8269, val_acc: 0.5474\n",
      "Epoch [855], train_loss: 0.0000, val_loss: 12.8268, val_acc: 0.5490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [856], train_loss: 0.0000, val_loss: 12.8272, val_acc: 0.5490\n",
      "Epoch [857], train_loss: 0.0000, val_loss: 12.8261, val_acc: 0.5490\n",
      "Epoch [858], train_loss: 0.0000, val_loss: 12.8268, val_acc: 0.5505\n",
      "Epoch [859], train_loss: 0.0000, val_loss: 12.8268, val_acc: 0.5505\n",
      "Epoch [860], train_loss: 0.0000, val_loss: 12.8261, val_acc: 0.5505\n",
      "Epoch [861], train_loss: 0.0000, val_loss: 12.8260, val_acc: 0.5505\n",
      "Epoch [862], train_loss: 0.0000, val_loss: 12.8253, val_acc: 0.5505\n",
      "Epoch [863], train_loss: 0.0000, val_loss: 12.8260, val_acc: 0.5505\n",
      "Epoch [864], train_loss: 0.0000, val_loss: 12.8262, val_acc: 0.5505\n",
      "Epoch [865], train_loss: 0.0000, val_loss: 12.8256, val_acc: 0.5505\n",
      "Epoch [866], train_loss: 0.0000, val_loss: 12.8260, val_acc: 0.5505\n",
      "Epoch [867], train_loss: 0.0000, val_loss: 12.8255, val_acc: 0.5505\n",
      "Epoch [868], train_loss: 0.0000, val_loss: 12.8254, val_acc: 0.5505\n",
      "Epoch [869], train_loss: 0.0000, val_loss: 12.8258, val_acc: 0.5474\n",
      "Epoch [870], train_loss: 0.0000, val_loss: 12.8251, val_acc: 0.5474\n",
      "Epoch [871], train_loss: 0.0000, val_loss: 12.8251, val_acc: 0.5474\n",
      "Epoch [872], train_loss: 0.0000, val_loss: 12.8252, val_acc: 0.5474\n",
      "Epoch [873], train_loss: 0.0000, val_loss: 12.8251, val_acc: 0.5474\n",
      "Epoch [874], train_loss: 0.0000, val_loss: 12.8244, val_acc: 0.5474\n",
      "Epoch [875], train_loss: 0.0000, val_loss: 12.8241, val_acc: 0.5474\n",
      "Epoch [876], train_loss: 0.0000, val_loss: 12.8243, val_acc: 0.5474\n",
      "Epoch [877], train_loss: 0.0000, val_loss: 12.8241, val_acc: 0.5474\n",
      "Epoch [878], train_loss: 0.0000, val_loss: 12.8233, val_acc: 0.5474\n",
      "Epoch [879], train_loss: 0.0000, val_loss: 12.8234, val_acc: 0.5474\n",
      "Epoch [880], train_loss: 0.0000, val_loss: 12.8229, val_acc: 0.5474\n",
      "Epoch [881], train_loss: 0.0000, val_loss: 12.8231, val_acc: 0.5474\n",
      "Epoch [882], train_loss: 0.0000, val_loss: 12.8227, val_acc: 0.5474\n",
      "Epoch [883], train_loss: 0.0000, val_loss: 12.8235, val_acc: 0.5474\n",
      "Epoch [884], train_loss: 0.0000, val_loss: 12.8234, val_acc: 0.5474\n",
      "Epoch [885], train_loss: 0.0000, val_loss: 12.8234, val_acc: 0.5474\n",
      "Epoch [886], train_loss: 0.0000, val_loss: 12.8222, val_acc: 0.5458\n",
      "Epoch [887], train_loss: 0.0000, val_loss: 12.8231, val_acc: 0.5458\n",
      "Epoch [888], train_loss: 0.0000, val_loss: 12.8223, val_acc: 0.5458\n",
      "Epoch [889], train_loss: 0.0000, val_loss: 12.8227, val_acc: 0.5458\n",
      "Epoch [890], train_loss: 0.0000, val_loss: 12.8225, val_acc: 0.5458\n",
      "Epoch [891], train_loss: 0.0000, val_loss: 12.8221, val_acc: 0.5443\n",
      "Epoch [892], train_loss: 0.0000, val_loss: 12.8225, val_acc: 0.5443\n",
      "Epoch [893], train_loss: 0.0000, val_loss: 12.8222, val_acc: 0.5443\n",
      "Epoch [894], train_loss: 0.0000, val_loss: 12.8223, val_acc: 0.5443\n",
      "Epoch [895], train_loss: 0.0000, val_loss: 12.8220, val_acc: 0.5443\n",
      "Epoch [896], train_loss: 0.0000, val_loss: 12.8227, val_acc: 0.5427\n",
      "Epoch [897], train_loss: 0.0000, val_loss: 12.8227, val_acc: 0.5427\n",
      "Epoch [898], train_loss: 0.0000, val_loss: 12.8224, val_acc: 0.5427\n",
      "Epoch [899], train_loss: 0.0000, val_loss: 12.8221, val_acc: 0.5443\n",
      "Epoch [900], train_loss: 0.0000, val_loss: 12.8227, val_acc: 0.5443\n",
      "Epoch [901], train_loss: 0.0000, val_loss: 12.8226, val_acc: 0.5458\n",
      "Epoch [902], train_loss: 0.0000, val_loss: 12.8221, val_acc: 0.5458\n",
      "Epoch [903], train_loss: 0.0000, val_loss: 12.8218, val_acc: 0.5458\n",
      "Epoch [904], train_loss: 0.0000, val_loss: 12.8216, val_acc: 0.5458\n",
      "Epoch [905], train_loss: 0.0000, val_loss: 12.8222, val_acc: 0.5458\n",
      "Epoch [906], train_loss: 0.0000, val_loss: 12.8222, val_acc: 0.5458\n",
      "Epoch [907], train_loss: 0.0000, val_loss: 12.8217, val_acc: 0.5458\n",
      "Epoch [908], train_loss: 0.0000, val_loss: 12.8221, val_acc: 0.5458\n",
      "Epoch [909], train_loss: 0.0000, val_loss: 12.8220, val_acc: 0.5458\n",
      "Epoch [910], train_loss: 0.0000, val_loss: 12.8221, val_acc: 0.5458\n",
      "Epoch [911], train_loss: 0.0000, val_loss: 12.8222, val_acc: 0.5458\n",
      "Epoch [912], train_loss: 0.0000, val_loss: 12.8207, val_acc: 0.5458\n",
      "Epoch [913], train_loss: 0.0000, val_loss: 12.8214, val_acc: 0.5458\n",
      "Epoch [914], train_loss: 0.0000, val_loss: 12.8220, val_acc: 0.5458\n",
      "Epoch [915], train_loss: 0.0000, val_loss: 12.8216, val_acc: 0.5458\n",
      "Epoch [916], train_loss: 0.0000, val_loss: 12.8205, val_acc: 0.5458\n",
      "Epoch [917], train_loss: 0.0000, val_loss: 12.8215, val_acc: 0.5458\n",
      "Epoch [918], train_loss: 0.0000, val_loss: 12.8211, val_acc: 0.5458\n",
      "Epoch [919], train_loss: 0.0000, val_loss: 12.8207, val_acc: 0.5458\n",
      "Epoch [920], train_loss: 0.0000, val_loss: 12.8208, val_acc: 0.5458\n",
      "Epoch [921], train_loss: 0.0000, val_loss: 12.8207, val_acc: 0.5458\n",
      "Epoch [922], train_loss: 0.0000, val_loss: 12.8216, val_acc: 0.5458\n",
      "Epoch [923], train_loss: 0.0000, val_loss: 12.8209, val_acc: 0.5458\n",
      "Epoch [924], train_loss: 0.0000, val_loss: 12.8207, val_acc: 0.5443\n",
      "Epoch [925], train_loss: 0.0000, val_loss: 12.8214, val_acc: 0.5458\n",
      "Epoch [926], train_loss: 0.0000, val_loss: 12.8207, val_acc: 0.5458\n",
      "Epoch [927], train_loss: 0.0000, val_loss: 12.8203, val_acc: 0.5474\n",
      "Epoch [928], train_loss: 0.0000, val_loss: 12.8209, val_acc: 0.5474\n",
      "Epoch [929], train_loss: 0.0000, val_loss: 12.8218, val_acc: 0.5474\n",
      "Epoch [930], train_loss: 0.0000, val_loss: 12.8215, val_acc: 0.5474\n",
      "Epoch [931], train_loss: 0.0000, val_loss: 12.8204, val_acc: 0.5474\n",
      "Epoch [932], train_loss: 0.0000, val_loss: 12.8211, val_acc: 0.5474\n",
      "Epoch [933], train_loss: 0.0000, val_loss: 12.8209, val_acc: 0.5474\n",
      "Epoch [934], train_loss: 0.0000, val_loss: 12.8228, val_acc: 0.5474\n",
      "Epoch [935], train_loss: 0.0000, val_loss: 12.8212, val_acc: 0.5474\n",
      "Epoch [936], train_loss: 0.0000, val_loss: 12.8213, val_acc: 0.5474\n",
      "Epoch [937], train_loss: 0.0000, val_loss: 12.8206, val_acc: 0.5474\n",
      "Epoch [938], train_loss: 0.0000, val_loss: 12.8210, val_acc: 0.5474\n",
      "Epoch [939], train_loss: 0.0000, val_loss: 12.8217, val_acc: 0.5474\n",
      "Epoch [940], train_loss: 0.0000, val_loss: 12.8229, val_acc: 0.5474\n",
      "Epoch [941], train_loss: 0.0000, val_loss: 12.8219, val_acc: 0.5474\n",
      "Epoch [942], train_loss: 0.0000, val_loss: 12.8220, val_acc: 0.5474\n",
      "Epoch [943], train_loss: 0.0000, val_loss: 12.8215, val_acc: 0.5474\n",
      "Epoch [944], train_loss: 0.0000, val_loss: 12.8216, val_acc: 0.5474\n",
      "Epoch [945], train_loss: 0.0000, val_loss: 12.8218, val_acc: 0.5474\n",
      "Epoch [946], train_loss: 0.0000, val_loss: 12.8215, val_acc: 0.5474\n",
      "Epoch [947], train_loss: 0.0000, val_loss: 12.8217, val_acc: 0.5474\n",
      "Epoch [948], train_loss: 0.0000, val_loss: 12.8235, val_acc: 0.5490\n",
      "Epoch [949], train_loss: 0.0000, val_loss: 12.8225, val_acc: 0.5474\n",
      "Epoch [950], train_loss: 0.0000, val_loss: 12.8241, val_acc: 0.5490\n",
      "Epoch [951], train_loss: 0.0000, val_loss: 12.8234, val_acc: 0.5490\n",
      "Epoch [952], train_loss: 0.0000, val_loss: 12.8230, val_acc: 0.5474\n",
      "Epoch [953], train_loss: 0.0000, val_loss: 12.8239, val_acc: 0.5490\n",
      "Epoch [954], train_loss: 0.0000, val_loss: 12.8228, val_acc: 0.5490\n",
      "Epoch [955], train_loss: 0.0000, val_loss: 12.8223, val_acc: 0.5490\n",
      "Epoch [956], train_loss: 0.0000, val_loss: 12.8241, val_acc: 0.5490\n",
      "Epoch [957], train_loss: 0.0000, val_loss: 12.8241, val_acc: 0.5490\n",
      "Epoch [958], train_loss: 0.0000, val_loss: 12.8227, val_acc: 0.5490\n",
      "Epoch [959], train_loss: 0.0000, val_loss: 12.8239, val_acc: 0.5490\n",
      "Epoch [960], train_loss: 0.0000, val_loss: 12.8230, val_acc: 0.5490\n",
      "Epoch [961], train_loss: 0.0000, val_loss: 12.8235, val_acc: 0.5490\n",
      "Epoch [962], train_loss: 0.0000, val_loss: 12.8243, val_acc: 0.5490\n",
      "Epoch [963], train_loss: 0.0000, val_loss: 12.8247, val_acc: 0.5490\n",
      "Epoch [964], train_loss: 0.0000, val_loss: 12.8239, val_acc: 0.5490\n",
      "Epoch [965], train_loss: 0.0000, val_loss: 12.8232, val_acc: 0.5490\n",
      "Epoch [966], train_loss: 0.0000, val_loss: 12.8242, val_acc: 0.5490\n",
      "Epoch [967], train_loss: 0.0000, val_loss: 12.8246, val_acc: 0.5490\n",
      "Epoch [968], train_loss: 0.0000, val_loss: 12.8239, val_acc: 0.5490\n",
      "Epoch [969], train_loss: 0.0000, val_loss: 12.8251, val_acc: 0.5490\n",
      "Epoch [970], train_loss: 0.0000, val_loss: 12.8252, val_acc: 0.5505\n",
      "Epoch [971], train_loss: 0.0000, val_loss: 12.8269, val_acc: 0.5490\n",
      "Epoch [972], train_loss: 0.0000, val_loss: 12.8257, val_acc: 0.5505\n",
      "Epoch [973], train_loss: 0.0000, val_loss: 12.8258, val_acc: 0.5505\n",
      "Epoch [974], train_loss: 0.0000, val_loss: 12.8266, val_acc: 0.5505\n",
      "Epoch [975], train_loss: 0.0000, val_loss: 12.8269, val_acc: 0.5505\n",
      "Epoch [976], train_loss: 0.0000, val_loss: 12.8256, val_acc: 0.5505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [977], train_loss: 0.0000, val_loss: 12.8279, val_acc: 0.5505\n",
      "Epoch [978], train_loss: 0.0000, val_loss: 12.8277, val_acc: 0.5505\n",
      "Epoch [979], train_loss: 0.0000, val_loss: 12.8271, val_acc: 0.5505\n",
      "Epoch [980], train_loss: 0.0000, val_loss: 12.8291, val_acc: 0.5505\n",
      "Epoch [981], train_loss: 0.0000, val_loss: 12.8287, val_acc: 0.5521\n",
      "Epoch [982], train_loss: 0.0000, val_loss: 12.8289, val_acc: 0.5521\n",
      "Epoch [983], train_loss: 0.0000, val_loss: 12.8289, val_acc: 0.5521\n",
      "Epoch [984], train_loss: 0.0000, val_loss: 12.8291, val_acc: 0.5521\n",
      "Epoch [985], train_loss: 0.0000, val_loss: 12.8299, val_acc: 0.5521\n",
      "Epoch [986], train_loss: 0.0000, val_loss: 12.8298, val_acc: 0.5521\n",
      "Epoch [987], train_loss: 0.0000, val_loss: 12.8312, val_acc: 0.5521\n",
      "Epoch [988], train_loss: 0.0000, val_loss: 12.8305, val_acc: 0.5521\n",
      "Epoch [989], train_loss: 0.0000, val_loss: 12.8304, val_acc: 0.5521\n",
      "Epoch [990], train_loss: 0.0000, val_loss: 12.8305, val_acc: 0.5536\n",
      "Epoch [991], train_loss: 0.0000, val_loss: 12.8310, val_acc: 0.5521\n",
      "Epoch [992], train_loss: 0.0000, val_loss: 12.8328, val_acc: 0.5521\n",
      "Epoch [993], train_loss: 0.0000, val_loss: 12.8322, val_acc: 0.5521\n",
      "Epoch [994], train_loss: 0.0000, val_loss: 12.8325, val_acc: 0.5521\n",
      "Epoch [995], train_loss: 0.0000, val_loss: 12.8334, val_acc: 0.5521\n",
      "Epoch [996], train_loss: 0.0000, val_loss: 12.8326, val_acc: 0.5536\n",
      "Epoch [997], train_loss: 0.0000, val_loss: 12.8321, val_acc: 0.5536\n",
      "Epoch [998], train_loss: 0.0000, val_loss: 12.8326, val_acc: 0.5536\n",
      "Epoch [999], train_loss: 0.0000, val_loss: 12.8341, val_acc: 0.5536\n",
      "Epoch [1000], train_loss: 0.0000, val_loss: 12.8344, val_acc: 0.5536\n",
      "Epoch [1001], train_loss: 0.0000, val_loss: 12.8356, val_acc: 0.5521\n",
      "Epoch [1002], train_loss: 0.0000, val_loss: 12.8354, val_acc: 0.5536\n",
      "Epoch [1003], train_loss: 0.0000, val_loss: 12.8346, val_acc: 0.5521\n",
      "Epoch [1004], train_loss: 0.0000, val_loss: 12.8360, val_acc: 0.5521\n",
      "Epoch [1005], train_loss: 0.0000, val_loss: 12.8366, val_acc: 0.5521\n",
      "Epoch [1006], train_loss: 0.0000, val_loss: 12.8372, val_acc: 0.5521\n",
      "Epoch [1007], train_loss: 0.0000, val_loss: 12.8380, val_acc: 0.5521\n",
      "Epoch [1008], train_loss: 0.0000, val_loss: 12.8383, val_acc: 0.5521\n",
      "Epoch [1009], train_loss: 0.0000, val_loss: 12.8384, val_acc: 0.5521\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "model1 = TimeSeriesCnnModel()\n",
    "model1.to(device)\n",
    "to_device(model1, device);\n",
    "history = fit(num_epochs, lr, model1, true_dl, true_dl_test, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"epoch\": num_epochs,\n",
    "    \"model1_state_dict\": model1.state_dict(),\n",
    "}, \"./RESULTS/model-true-1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7edcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "conv_dl = DeviceDataLoader(conv_dl, device)\n",
    "conv_dl_test = DeviceDataLoader(conv_dl_test, device)\n",
    "model2 = TimeSeriesCnnModel()\n",
    "model2.to(device)\n",
    "to_device(model2, device);\n",
    "history = fit(num_epochs, lr, model2, conv_dl,conv_dl_test, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"epoch\": num_epochs,\n",
    "    \"model2_state_dict\": model2.state_dict(),\n",
    "}, \"./RESULTS/model-conv-1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0a2922",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "conv_inc_dl = DeviceDataLoader(conv_inc_dl, device)\n",
    "conv_inc_dl_test = DeviceDataLoader(conv_inc_dl_test, device)\n",
    "model3 = TimeSeriesCnnModel()\n",
    "model3.to(device)\n",
    "to_device(model3, device);\n",
    "history = fit(num_epochs, lr, model3, conv_inc_dl, conv_inc_dl_test, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9888c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"epoch\": num_epochs,\n",
    "    \"model3_state_dict\": model3.state_dict(),\n",
    "}, \"./RESULTS/model-inc-1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffb523",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cc4ca6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesCnnModel(\n",
       "  (network): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (6): ReLU()\n",
       "    (7): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (11): ReLU()\n",
       "    (12): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Flatten(start_dim=1, end_dim=-1)\n",
       "    (16): Linear(in_features=12800, out_features=1024, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2031a5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 12.838408470153809, 'val_acc': 0.5520833730697632}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train: true, test: true\n",
    "evaluate(model1, true_dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "583af9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 25.529077529907227, 'val_acc': 0.3482142984867096}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train: true, test: conv\n",
    "evaluate(model1, conv_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1a546dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 25.297374725341797, 'val_acc': 0.4073423147201538}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train: true, test: conv-inc\n",
    "evaluate(model1, conv_inc_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "78f14b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.0, 'val_acc': 1.0}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train: conv, test: conv\n",
    "evaluate(model2, conv_dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d3f62ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 55.46001052856445, 'val_acc': 0.5008548498153687}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train: conv, test: true\n",
    "evaluate(model2, true_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train: conv-inc, test: conv-inc\n",
    "evaluate(model3, conv_inc_dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1a452a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 6.246950626373291, 'val_acc': 0.5075988173484802}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train: conv-inc, test: true\n",
    "evaluate(model3, true_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6fb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c25f8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
